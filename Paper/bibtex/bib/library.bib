Automatically generated by Mendeley Desktop 1.11
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@phdthesis{Effertz2009,
abstract = {Diese Dissertation behandelt die Fahrzeugarchitektur sowie die darin enthaltene maschinelle Umfeldwahrnehmung f\"{u}r eine autonome Fahrt in komplexer urabaner Umgebung},
annote = {CarOLO Cup Ergebnisse},
author = {Effertz, Jan},
file = {:Users/paul/Dropbox/Promotion/Literatur/2009 - Effertz - Autonome Fahrzeugf\"{u}hrung in urbaner Umgebung durch Kombination objekt- und kartenbasierter Umfeldmodelle.pdf:pdf},
keywords = {Bahnplanung,Bayes'sche Filter},
mendeley-tags = {Bahnplanung,Bayes'sche Filter},
school = {Technische Universit\"{a}t Carolo-Wilhelmina zu Braunschweig},
title = {{Autonome Fahrzeugf\"{u}hrung in urbaner Umgebung durch Kombination objekt- und kartenbasierter Umfeldmodelle}},
year = {2009}
}
@misc{Romero2004,
abstract = {A new method to detect 3D Obstacles using a stereo vision system and a 2D laser range finder is presented. Laser range finder measures distance to obstacles, but only on a plane parallel to the floor; and stereo vision is not able to estimate distances to surfaces with little or no texture at all. This paper explores a form to take advantages of both kind of sensors. The main idea is to project 3D points detected by the laser telemeter in the form of initial values for pixel disparities into a trinocular stereo vision system. Experimental tests using a mobile robot in a indoor environment showed promising results.},
author = {Romero, Leonardo and N\'{u}\~{n}ez, Adri\'{a}n and Bravo, Sergio and Gamboa, Luis E},
booktitle = {Advances in Artificial Intelligence ??? IBERAMIA 2004},
file = {:Users/paul/Dropbox/Promotion/Literatur/2004 - Romero et al. - Fusing a Laser Range Finder and a Stereo Vision System to Detect Obstacles in 3D.pdf:pdf},
pages = {555--561},
title = {{Fusing a Laser Range Finder and a Stereo Vision System to Detect Obstacles in 3D}},
url = {http://www.springerlink.com/content/kcq8kae6vk1qt2j1},
year = {2004}
}
@article{Kelly1994a,
author = {Kelly, Alonzo},
file = {:Users/paul/Dropbox/Promotion/Literatur/1994 - Kelly - Essential Kinematics for Autonomous Vehicles.pdf:pdf},
title = {{Essential Kinematics for Autonomous Vehicles}},
url = {http://oai.dtic.mil/oai/oai?verb=getRecord\&metadataPrefix=html\&identifier=ADA282456},
year = {1994}
}
@article{Lehtomaki2010,
abstract = {Pole-like objects such as traffic signs, lamp posts and tree trunks are an important part of road environments. An automatic method was developed for the extraction of pole-like objects from VLS data. The},
author = {Lehtom\"{a}ki, Matti and Jaakkola, Anttoni and Hyypp\"{a}, Juha and Kukko, Antero and Kaartinen, Harri},
doi = {10.3390/rs2030641},
file = {:Users/paul/Dropbox/Promotion/Literatur/2010 - Lehtom\"{a}ki et al. - Detection of Vertical Pole-Like Objects in a Road Environment Using Vehicle-Based Laser Scanning Data.pdf:pdf},
issn = {2072-4292},
journal = {Remote Sensing},
keywords = {feature extraction,mobile mapping,traffic sign,tree trunk,utility pole,vehicle-based laser scanning},
month = feb,
number = {3},
pages = {641--664},
title = {{Detection of Vertical Pole-Like Objects in a Road Environment Using Vehicle-Based Laser Scanning Data}},
url = {http://www.mdpi.com/2072-4292/2/3/641/},
volume = {2},
year = {2010}
}
@article{Betge-Brezetz1994,
abstract = {In this paper, we focus on some perceptual functions required by a generic task ???GOTO??? in natural environments; in previous works, only geometrical modeling has been used to deal with two fundamental tasks: landmark extraction and recognition for sensor-based motion control or robot localization, and terrain modeling for motion planning. Geometrical representations alone lead to a bulky model, and, after some iterations, to a combinatorial explosion. We present here, higher level representations; from a range image, given some assumptions on the perceived scene (even ground with few objects), we propose a segmentation algorithm to extract simple semantical representations for the ground and the objects; then, we can analyze the relative positions of the objects to build a topological scene description. Both models constitute the scene model, needed for further incremental environment modeling},
author = {Betge-Brezetz, S. and Chatila, R. and Devy, M.},
journal = {Robotics and Automation, 1994. Proceedings., 1994 IEEE International Conference on},
pages = {730--736},
title = {{Natural scene understanding for mobile robot navigation}},
url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=351400},
year = {1994}
}
@article{Miyajima2013,
annote = {\"{A}hnlich dem BMBF Projekt "Adaptive, lernende Systeme"},
author = {Miyajima, Chiyomi and Angkititrakul, Pongtep and Takeda, Kazuya},
doi = {10.1017/ATSIP.2013.2},
file = {:Users/paul/Dropbox/Promotion/Literatur/2013 - Miyajima, Angkititrakul, Takeda - Behavior signal processing for vehicle applications.pdf:pdf},
issn = {2048-7703},
journal = {APSIPA Transactions on Signal and Information Processing},
keywords = {Behavioral signal processing,Driver behavior,Multi-modal driving signals,On-the-road},
language = {English},
month = mar,
pages = {e2},
publisher = {Cambridge University Press},
title = {{Behavior signal processing for vehicle applications}},
url = {http://journals.cambridge.org/abstract\_S2048770313000024},
volume = {2},
year = {2013}
}
@article{Hofmann2010,
author = {Hofmann, S and Schulze, M J and Sester, M and Brenner, Claus},
file = {:Users/paul/Dropbox/Promotion/Literatur/2010 - Hofmann et al. - QUALITY ASSESSMENT OF LANDMARK BASED POSITIONING USING STEREO CAMERAS.pdf:pdf},
journal = {Information Sciences},
keywords = {accuracy,geometry,mobile mapping,navigation,quality,reference data,simulation,stereo camera},
pages = {85--90},
title = {{QUALITY ASSESSMENT OF LANDMARK BASED POSITIONING USING STEREO CAMERAS}},
volume = {38},
year = {2010}
}
@article{Schubert2008,
author = {Schubert, Robin and Richter, Eric and Wanielik, Gerd},
file = {:Users/paul/Dropbox/Promotion/Literatur/2008 - Schubert, Richter, Wanielik - Comparison and evaluation of advanced motion models for vehicle tracking.pdf:pdf},
journal = {Information Fusion, 2008 \ldots},
keywords = {motion models,ukf,vehicle tracking},
number = {1},
pages = {730--735},
title = {{Comparison and evaluation of advanced motion models for vehicle tracking}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4632283},
year = {2008}
}
@article{Vandorpe1996,
abstract = {In this paper, a new mathematically exact algorithm is described for dynamic map building with geometrical primitives for a mobile robot. The dynamic map is built up using a 20 rangefinder mounted on the mobile robot LiAS??? which is navigating in the environment. The dynamic map can be used for either planning or localisation purposes. The map is composed of line segments and circles. The parameters describing the geometrical primitives are provided with uncertainties which are used in the matching phase and which are necessary if the map is used for localisation. This paper describes in detail how the uncertainty on the robot position and the uncertainty on a single range measurement leads to the uncertainty on the parameters of a geometrical primitive. Promising experimental results obtained by the algorithm in real unstructured environments are presented},
author = {Vandorpe, J and Brussel, H Van},
file = {:Users/paul/Dropbox/Promotion/Literatur/1996 - Vandorpe, Brussel - Exact dynamic map building for a mobile robot using geometrical primitives produced by a 2D range finder.pdf:pdf},
journal = {Robotics and Automation,},
number = {April},
pages = {901--908},
title = {{Exact dynamic map building for a mobile robot using geometrical primitives produced by a 2D range finder}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=503887},
year = {1996}
}
@techreport{Gries2008,
author = {Gries, Jan Christoph and Girlich, Jan and Zhang, Prof Jianwei and Klimentjew, Denis},
file = {:Users/paul/Dropbox/Promotion/Literatur/2008 - Gries et al. - ibeo LUX Laserscanner.pdf:pdf},
pages = {1--17},
title = {{ibeo LUX Laserscanner}},
year = {2008}
}
@article{Shi1996,
annote = {Nur mal so ein \"{U}berblick, keine wirklichen Informationen darin},
author = {Shi, Y. and Shibasaki, R. and Shi, Z. C.},
file = {:Users/paul/Dropbox/Promotion/Literatur/1996 - Shi, Shibasaki, Shi - TOWARDS AUTOMATIC ROAD MAPPING BY FUSING VEHICLE-BORNE MULTI-SENSOR DATA.pdf:pdf},
journal = {Archives},
keywords = {automatic object extraction and,close-range,direct-georeferencing,integrated sensor system,mobile mapping system,multi-sensor data fusion,photogrammetry,recognition},
title = {{TOWARDS AUTOMATIC ROAD MAPPING BY FUSING VEHICLE-BORNE MULTI-SENSOR DATA}},
year = {1996}
}
@inproceedings{Andersen2008,
author = {Andersen, J. and Andersen, N. and Ravn, Ole},
booktitle = {Experimental Robotics},
file = {:Users/paul/Dropbox/Promotion/Literatur/2008 - Andersen, Andersen, Ravn - Vision assisted laser scanner navigation for autonomous robots.pdf:pdf},
pages = {111--120},
publisher = {Springer},
title = {{Vision assisted laser scanner navigation for autonomous robots}},
url = {http://www.springerlink.com/index/ar0816740gx109kv.pdf},
year = {2008}
}
@phdthesis{Gregor2002,
author = {Gregor, Rudolf},
file = {:Users/paul/Dropbox/Promotion/Literatur/2002 - Gregor - F\"{a}higkeiten zur Missionsdurchf\"{u}hrung und Landmarkennavigation.pdf:pdf},
publisher = {Universt\"{a}t der Bundeswehr M\"{u}chen, Universit\"{a}tsbibliothek},
title = {{F\"{a}higkeiten zur Missionsdurchf\"{u}hrung und Landmarkennavigation}},
url = {http://ub.unibw-muenchen.de/dissertationen/ediss/gregor-rudolf/meta.html},
year = {2002}
}
@article{Lacroix1997,
author = {Lacroix, Simon},
file = {:Users/paul/Dropbox/Promotion/Literatur/1997 - Lacroix - Motion and perception strategies for outdoor mobile robot navigation in unknown environments.pdf:pdf},
journal = {Experimental Robotics IV},
title = {{Motion and perception strategies for outdoor mobile robot navigation in unknown environments}},
url = {http://www.springerlink.com/index/5r3j883k1l8m5m73.pdf},
year = {1997}
}
@article{Brenner2010,
author = {Brenner, Claus},
file = {:Users/paul/Dropbox/Promotion/Literatur/2010 - Brenner - Vehicle localization using landmarks obtained by a lidar mobile mapping system(2).pdf:pdf},
journal = {Proceedings of the Photogrammetric Computer Vision \ldots},
keywords = {accuracy,feature extraction,localization,mapping,mobile laser scanning},
pages = {139--144},
title = {{Vehicle localization using landmarks obtained by a lidar mobile mapping system}},
url = {http://www.isprs.org/proceedings/xxxviii/part3/a/pdf/zwi/25-XXXVIII-part3A.pdf},
volume = {XXXVIII},
year = {2010}
}
@inproceedings{Fuerstenberg2000,
author = {Fuerstenberg, Kay and Hipp, J and Liebram, A and Others},
booktitle = {Proceedings of ITS},
file = {:Users/paul/Dropbox/Promotion/Literatur/2000 - Fuerstenberg et al. - A Laserscanner for detailed traffic data collection and traffic control.pdf:pdf},
pages = {1--4},
publisher = {Citeseer},
title = {{A Laserscanner for detailed traffic data collection and traffic control}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.24.4950\&amp;rep=rep1\&amp;type=pdf},
year = {2000}
}
@inproceedings{Talukder2002a,
author = {Talukder, A and Manduchi, R and Rankin, A and Matthies, L},
booktitle = {Intelligent Vehicle Symposium, 2002. IEEE},
file = {:Users/paul/Dropbox/Promotion/Literatur/2002 - Talukder et al. - Fast and reliable obstacle detection and segmentation for cross-country navigation.pdf:pdf},
keywords = {3-d vision,autonomous navigation,classification,geometrical,obstacle detection,terrain perception},
number = {818},
pages = {610--618},
publisher = {IEEE},
title = {{Fast and reliable obstacle detection and segmentation for cross-country navigation}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1188019},
volume = {2},
year = {2002}
}
@article{Penarrocha2010,
abstract = {In this work, the parameter identification for systems with scarce measurements is addressed. A linear plant is assumed and its output is assumed to be available only at sporadic instants of time and affected by noise measurement. The identification is carried out estimating the missing outputs in order to construct the regression vector needed by the parameter estimation algorithm and using the available output information not only to update the estimated parameter vector, but also to update the regression vector in order to fasten the convergence of the algorithm. The problem is addressed with an adaptive extended Kalman filter that estimates and correct both the parameters and the regression vector, allowing to improve the convergence speed of the algorithm with respect to other existing ones on the literature as it is shown with several examples.},
author = {Penarrocha, I. and Sanchis, R.},
doi = {10.1109/CDC.2010.5717484},
isbn = {978-1-4244-7744-9},
issn = {0743-1546},
journal = {49th IEEE Conference on Decision and Control (CDC)},
keywords = {Algorithm initialization,Kalman filter,Least squares,Networked Control Systems,Output estimation,Parameter estimation,Pseudo-Linear Recursive Identification,Randomly missing outputs},
pages = {1165--1170},
title = {{Adaptive extended Kalman filter for recursive identification under missing data}},
year = {2010}
}
@article{Yang2003,
author = {Yang, Ruigang},
file = {:Users/paul/Dropbox/Promotion/Literatur/2003 - Yang - Multi-resolution real-time stereo on commodity graphics hardware.pdf:pdf},
journal = {Computer Vision and Pattern},
pages = {1--7},
title = {{Multi-resolution real-time stereo on commodity graphics hardware}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1211356},
year = {2003}
}
@article{Lenz1987,
author = {Lenz, R and Tsai, R},
file = {:Users/paul/Dropbox/Promotion/Literatur/1987 - Lenz, Tsai - Techniques for calibration of the scale factor and image center for high accuracy 3D machine vision metrology.pdf:pdf},
journal = {Robotics and Automation. Proceedings. 1987 \ldots},
pages = {68--75},
title = {{Techniques for calibration of the scale factor and image center for high accuracy 3D machine vision metrology}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1088012},
year = {1987}
}
@article{Pandey2010,
abstract = {The procedure requires a planar checkerboard pattern to be observed simultaneously from the laser scanner and the camera system from a minimum of 3 views. The normal of the planar surface and 3D points lying on the surface constrain the relative position and orientation of the laser scanner and the omnidirectional camera system. These constraints can be used to form a non-linear optimization problem that is solved for the extrinsic calibration parameters and the covariance associated with the estimated parameters.},
author = {Pandey, Gaurav and McBride, J},
file = {:Users/paul/Dropbox/Promotion/Literatur/2010 - Pandey, McBride - Extrinsic calibration of a 3d laser scanner and an omnidirectional camera.pdf:pdf},
journal = {7th IFAC Symposium},
keywords = {3d laser scanner,omnidirectional camera,sensor calibration},
pages = {2--7},
title = {{Extrinsic calibration of a 3d laser scanner and an omnidirectional camera}},
url = {http://robots.engin.umich.edu/publications/gpandey-2010a.pdf},
year = {2010}
}
@phdthesis{Skutek2006,
author = {Skutek, Michael},
file = {:Users/paul/Dropbox/Promotion/Literatur/2006 - Skutek - Ein PreCrash-System auf Basis multisensorieller Umgebungserfassung.pdf:pdf},
number = {September},
publisher = {Universit\"{a}tsbibliothek der Technischen Universit\"{a}t},
school = {Chemnitz},
title = {{Ein PreCrash-System auf Basis multisensorieller Umgebungserfassung}},
url = {http://deposit.ddb.de/cgi-bin/dokserv?idn=98753663x\&amp;dok\_var=d1\&amp;dok\_ext=pdf\&amp;filename=98753663x.pdf},
year = {2006}
}
@book{Lacroix1997a,
address = {London},
author = {Lacroix, Simon and Chatila, Raja and Khatib, Oussama and Salisbury, J.},
doi = {10.1007/BFb0035191},
editor = {Khatib, Oussama and Salisbury, J. Kenneth},
isbn = {3-540-76133-0},
keywords = {Engineering},
pages = {538--547},
publisher = {Springer-Verlag},
series = {Lecture Notes in Control and Information Sciences},
title = {{Experimental Robotics IV}},
url = {http://www.springerlink.com/content/5r3j883k1l8m5m73/},
volume = {223},
year = {1997}
}
@article{Stephen2001,
abstract = {An integrated multi-sensor vehicle navigation system is presented which uses a low cost rate gyro and differential odometry to supplement GPS under signal masking conditions such as tree foliage and urban canyons.},
author = {Stephen, J. and Lachapelle, G.},
file = {:Users/paul/Dropbox/Promotion/Literatur/2001 - Stephen, Lachapelle - Development and Testing of a GPS-Augmented Multi-Sensor Vehicle navigation system.pdf:pdf},
journal = {The Journal of Navigation},
pages = {297--319},
title = {{Development and Testing of a GPS-Augmented Multi-Sensor Vehicle navigation system}},
volume = {54},
year = {2001}
}
@article{Guivant2000,
author = {Guivant, Jose and Nebot, Eduardo},
journal = {Intelligent Autonomous},
title = {{Simultaneous localization and map building using natural features in outdoor environments}},
url = {http://isl.ecst.csuchico.edu/DOCS/Logs/Michael/Files/web\_link\_files/natural\_slam.pdf},
year = {2000}
}
@article{Kaempchen2010,
author = {Kaempchen, Nico and Waldmann, Peter and Homm, Florian and Ardelt, Michael},
file = {:Users/paul/Dropbox/Promotion/Literatur/2010 - Kaempchen et al. - Umfelderfassung f\"{u}r den Nothalteassistenten???ein System zum automatischen Anhalten bei pl\"{o}tzlich reduziert.pdf:pdf},
journal = {AAET, \ldots},
title = {{Umfelderfassung f\"{u}r den Nothalteassistenten???ein System zum automatischen Anhalten bei pl\"{o}tzlich reduzierter Fahrf\"{a}higkeit des Fahrers}},
url = {http://smartsenior.schmidt-works.de/dyn/mediaout.dhtml/-/server/Wissenswertes/Veroeffentlichungen/Vortraege/201004\_publikation\_DE\_01/publikation\_DE\_01/@teaser\_long/@s4/SmartSenior\_AAET\_BMW\_2010.pdf},
year = {2010}
}
@article{Loose2009,
author = {Loose, Heidi and Franke, Uwe},
file = {:Users/paul/Dropbox/Promotion/Literatur/2009 - Loose, Franke - Fahrbahnerkennung auf Landstra\ss en.pdf:pdf},
journal = {6. Workshop Fahrerassistenzsysteme},
title = {{Fahrbahnerkennung auf Landstra\ss en}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Fahrbahnerkennung+auf+Landstra?en\#0},
year = {2009}
}
@article{Wurm2010,
author = {Wurm, Kai M. and Hornung, Armin},
file = {:Users/paul/Dropbox/Promotion/Literatur/2010 - Wurm, Hornung - OctoMap A probabilistic, flexible, and compact 3D map representation for robotic systems.pdf:pdf},
journal = {practice in 3D},
title = {{OctoMap: A probabilistic, flexible, and compact 3D map representation for robotic systems}},
url = {http://ais.informatik.uni-freiburg.de/publications/papers/wurm10octomap.pdf},
year = {2010}
}
@article{Meierhold2010,
author = {Meierhold, N and Spehr, M and Schilling, A and Gumhold, S and Maas, H},
file = {:Users/paul/Dropbox/Promotion/Literatur/2010 - Meierhold et al. - Automatic Feature Matching Between Digital Images and 2D Representation of a 3D Laser Scanner Point Cloud.pdf:pdf},
journal = {International Archives of Photogrammetry Remote Sensing and Spatial Information Sciences},
keywords = {data fusion,feature matching,fundamental matrix,intensity image,ransac,sift,terrestrial laser scanning},
number = {5},
publisher = {Citeseer},
title = {{Automatic Feature Matching Between Digital Images and 2D Representation of a 3D Laser Scanner Point Cloud}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.169.8010\&amp;rep=rep1\&amp;type=pdf},
volume = {XXXVIII},
year = {2010}
}
@article{Wedel2009,
author = {Wedel, Andreas and Badino, Hern\'{a}n and Rabe, Clemens},
file = {:Users/paul/Dropbox/Promotion/Literatur/2009 - Wedel, Badino, Rabe - B-spline modeling of road surfaces with an application to free-space estimation.pdf:pdf},
journal = {Intelligent},
number = {4},
pages = {572--583},
title = {{B-spline modeling of road surfaces with an application to free-space estimation}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5200422},
volume = {10},
year = {2009}
}
@article{Doubek2008,
abstract = {In this paper, we present a method for detection and localization of vertical traffic infrastructure using video sequences recorded by a survey vehicle. Search for pole- like structures in the images creates initial 2D hypotheses. They are fused on the groundplane to form 3D hypotheses which are finally verified and classified by search for the dis- tinguished part of the infrastructure. Each step is followed by pruning the set of hypotheses using SVM classifier. The method was tested in a streetlight detection application with video sequences containing over one thousand streetlights.},
author = {Doubek, Petr and Per, Michal and Sochman, Jan},
file = {:Users/paul/Dropbox/Promotion/Literatur/2008 - Doubek, Per, Sochman - Mobile Mapping of Vertical Traffic Infrastructure.pdf:pdf},
journal = {Computer Vision Winter Workshop},
pages = {115--122},
title = {{Mobile Mapping of Vertical Traffic Infrastructure}},
url = {ftp://cmp.felk.cvut.cz/pub/cmp/articles/doubek/Doubek-CVWW2008.pdf},
year = {2008}
}
@phdthesis{Holt2004,
abstract = {In der vorliegenden Arbeit wird eine Mehrsensoranordnung zurWahrnehmung der Fahrum- gebung in Strassenfahrzeugen vorgestellt. Als Sensoren gelangen eine monochrome Video- kamera sowie ein Mehrstrahllaser zum Einsatz. Der Mehrstrahllaser hat die Aufgabe der Detektion von Objekten im Fernbereich und im peripheren Blickfeld, ist aufgrund seiner Eigenschaften aber nicht f\"{u}r die Feinvermessung oder Klassifikation von Objekten geeignet. Die Videokamera besitzt demgegen\"{u}ber ein eingeschr\"{a}nkteres Blickfeld als der Mehrstrahl- laser und liefert in diesem Bereich Informationen \"{u}ber den Fahrspurverlauf, sowie eine redundante, h\"{o}her aufgel\"{o}ste Vermessung der Objekte.},
author = {von Holt, V},
file = {:Users/paul/Dropbox/Promotion/Literatur/2004 - Holt - Integrale multisensorielle Fahrumgebungserfassung nach dem 4D-Ansatz.pdf:pdf},
school = {Universit\"{a}t der Bundeswehr M\"{u}nchen},
title = {{Integrale multisensorielle Fahrumgebungserfassung nach dem 4D-Ansatz}},
url = {http://ub.unibw-muenchen.de/dissertationen/ediss/holt-volker/meta.html},
year = {2004}
}
@article{Kwon2004,
author = {Kwon, S},
doi = {10.1016/j.autcon.2003.08.007},
file = {:Users/paul/Dropbox/Promotion/Literatur/2004 - Kwon - Fitting range data to primitives for rapid local 3D modeling using sparse range point clouds.pdf:pdf},
issn = {09265805},
journal = {Automation in Construction},
keywords = {3d workspace modeling,fitting and matching objects,merging objects,sparse range point clouds},
month = jan,
number = {1},
pages = {67--81},
title = {{Fitting range data to primitives for rapid local 3D modeling using sparse range point clouds}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0926580503000773},
volume = {13},
year = {2004}
}
@article{Bistrovs2012,
annote = {In this paper innovation based adaptive EKF for adapting R and Q was used in order to improve navigation system performance during GPS signal outages.},
author = {Bistrovs, V and Kluga, A},
file = {:Users/paul/Dropbox/Promotion/Literatur/2012 - Bistrovs, Kluga - Adaptive Extended Kalman Filter for Aided Inertial Navigation System.pdf:pdf},
journal = {Electronics \& Electrical Engineering},
number = {6},
title = {{Adaptive Extended Kalman Filter for Aided Inertial Navigation System.}},
url = {http://eejournal.ktu.lt/index.php/elt/article/viewFile/1818/1476},
volume = {6},
year = {2012}
}
@article{Mendes2004,
abstract = {In this paper we present a method of detection and tracking of moving objects (DATMO) using a laser range finder (LRF). The DATMO system is able to classify several kinds of objects and can be easily expanded to detect new ones. It is composed by three modules: scan segmentation; object classification using a suitable voting scheme of several object properties; and object tracking using a Kalman filter that takes the object type to increase the tracking performance into account. The goal is to design a collision avoidance algorithm to integrate a Cybercar vehicle, which uses the computed time-to-collision for each moving obstacle validated by the DATMO system.},
author = {Mendes, Abel and Bento, Luis Conde and Nunes, Urbano and Ieee, Member},
file = {:Users/paul/Dropbox/Promotion/Literatur/2004 - Mendes et al. - Multi-target detection and tracking with a laser scanner.pdf:pdf},
isbn = {0780383109},
journal = {Intelligent Vehicles Symposium, 2004 IEEE},
keywords = {Laserscanner},
mendeley-tags = {Laserscanner},
pages = {796--801},
title = {{Multi-target detection and tracking with a laser scanner}},
url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=1336486},
year = {2004}
}
@article{Rusu2011,
author = {Rusu, Radu Bogdan and Cousins, Steve},
doi = {10.1109/ICRA.2011.5980567},
file = {:Users/paul/Dropbox/Promotion/Literatur/2011 - Rusu, Cousins - 3D is here Point Cloud Library (PCL).pdf:pdf},
isbn = {978-1-61284-386-5},
journal = {2011 IEEE International Conference on Robotics and Automation},
month = may,
pages = {1--4},
publisher = {Ieee},
title = {{3D is here: Point Cloud Library (PCL)}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5980567},
year = {2011}
}
@inproceedings{Denzler1996,
author = {Denzler, J and Niemann, H},
booktitle = {DAGM-Symposium},
file = {:Users/paul/Dropbox/Promotion/Literatur/1996 - Denzler, Niemann - Echtzeitobjektverfolgung mit aktiven Strahlen.pdf:pdf},
number = {Informatik 5},
pages = {84--91},
title = {{Echtzeitobjektverfolgung mit aktiven Strahlen}},
url = {http://www5.informatik.uni-erlangen.de/Forschung/Publikationen/1996/Denzler96-EMA.pdf},
year = {1996}
}
@article{Trzebiatowski2004,
author = {von Trzebiatowski, MS and Gern, A},
file = {:Users/paul/Dropbox/Promotion/Literatur/2004 - Trzebiatowski, Gern - Detecting reflection posts-lane recognition on country roads.pdf:pdf},
journal = {Intelligent Vehicles},
pages = {304--309},
title = {{Detecting reflection posts-lane recognition on country roads}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1336399},
year = {2004}
}
@inproceedings{Hussain2005,
author = {Hussain, K.F. and Moussa, G.S.},
booktitle = {Information Technology: Coding and Computing, 2005. ITCC 2005. International Conference on},
file = {:Users/paul/Dropbox/Promotion/Literatur/2005 - Hussain, Moussa - Automatic vehicle classification system using range sensor.pdf:pdf},
isbn = {0769523153},
pages = {107--112},
publisher = {IEEE},
title = {{Automatic vehicle classification system using range sensor}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1425130},
volume = {2},
year = {2005}
}
@article{Miksch2010,
abstract = {In this paper we present a method to calibrate the extrinsic parameters of a monocular camera on a moving vehicle. The method is based on a homography between two camera shots. Therefore, only the road surface has to be visible in the pair of images. A reasonable definition of the vehicle coordinate system in combination with the use of epipolar geometry reduces the complexity to parameterize the underlying homography matrix. The extrinsic parameters are determined analytically by two correctly matched feature points located on the road surface. The final parameter set is determined by a recursive filter which considers various estimates over time. Results with a real-world video sequence indicate that the method is comparable to classical offline calibration techniques using objects of known geometry.},
author = {Miksch, Michael and Yang, Bin and Zimmermann, Klaus},
doi = {10.1109/IVS.2010.5548048},
issn = {19310587},
journal = {Camera},
pages = {832--839},
publisher = {IEEE},
title = {{Automatic Extrinsic Camera Self-Calibration Based on Homography and Epipolar Geometry}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5548048},
year = {2010}
}
@article{Nilsson1971,
author = {Nilsson, Nils J},
file = {:Users/paul/Dropbox/Promotion/Literatur/1971 - Nilsson - PROBLEM-SOLVING METHODS IN ARTIFICIAL INTELLIGENCE.pdf:pdf},
keywords = {A Star,A*},
mendeley-tags = {A Star,A*},
pages = {65--68},
title = {{PROBLEM-SOLVING METHODS IN ARTIFICIAL INTELLIGENCE}},
url = {http://www.cse.buffalo.edu/~rapaport/572/S02/nilsson.8puzzle.pdf},
year = {1971}
}
@article{Kaempchen2004a,
abstract = {In etablierten Fahrerassistenzsystemen basiert jede Applikation auf ihren eigenen Sensoren, die das Fahrzeugumfeld beobachten. Die Entwicklung zuk\"{u}nftiger, fortgeschrittener Fahrer- assistenzsysteme zeigt, dass mehrere Sensorsysteme notwendig sind, um die gew\"{u}nschte Zuverl\"{a}ssigkeit und Pr\"{a}zision der Assistenzfunktion zu erreichen. Es wird ein Sensorfusions- system vorgestellt, das basierend auf einem Laserscanner und Videosystem als allgemeine Plattform f\"{u}r mehrere Sicherheits- und Komfortapplikationen dient. Durch die Sensorfusion wird ein weites Blickfeld erreicht und die Sicherheit und Genauigkeit der Sch\"{a}tzungen in den relevanten Regionen signifikant erh\"{o}ht. Robuste Objektverfolgung und Klassifikation, Fahr- spursch\"{a}tzung und Fu\ss g\"{a}ngererkennung erm\"{o}glichen eine breite Unterst\"{u}tzung von Appli- kationen wie Fahrspurverlassenswarnung, Automatische Notbremsung, Stauassistent (ACC Stop\&Go), PreCrash und Fu\ss g\"{a}ngerschutz.},
author = {Kaempchen, Nico and Fuerstenberg, Kay and Dietmayer, Klaus},
file = {:Users/paul/Dropbox/Promotion/Literatur/2004 - Kaempchen, Fuerstenberg, Dietmayer - Ein Sensorfusionssystem f\"{u}r automotive Sicherheits- und Komfortapplikationen.pdf:pdf},
journal = {Aktive Sicherheit durch Fahrerassistenz},
keywords = {Fahrerassistenz,Laserscanner,Sensor Fusion,Video},
pages = {1--17},
title = {{Ein Sensorfusionssystem f\"{u}r automotive Sicherheits- und Komfortapplikationen}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Ein+Sensorfusionssystem+f?r+automotive+Sicherheits-+und+Komfortapplikationen\#0},
year = {2004}
}
@article{Wasielewski1995,
annote = {s/w Pattern und \"{a}hnliche Idee},
author = {Wasielewski, S and Strauss, O},
file = {:Users/paul/Dropbox/Promotion/Literatur/1995 - Wasielewski, Strauss - Calibration of a multi-sensor system laser rangefindercamera.pdf:pdf},
journal = {Intelligent Vehicles' 95 Symposium., \ldots},
pages = {472--477},
title = {{Calibration of a multi-sensor system laser rangefinder/camera}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=528327},
year = {1995}
}
@article{Ohl2011b,
abstract = {In diesem Beitrag wurde ein Kontur schatzendes Kalman lter fur ein urbanes Umfeld vorgestellt. Dieses klassi ziert die Messdaten zunachst auf Basis der Turningfunktion und fusioniert das Ergebnis mithilfe eines D-S-Filters. Bei geanderter Klassi kation wird nach der Aktualisierung des Zustandsvektors durch den Extended Kalman lter die Kontur des Tracks durch die klassi zierte ersetzt. Dies fuhrt zu einer erheblich verbesserten Beschreibung von hau g auftretenden Konturen bei gleichzeitiger Erhaltung der Flexibilitat des Frei-Form-Kontur-Objekthypothesenmodells fur unklassi zierte Objekthypothesen.},
annote = {        From Duplicate 1 (                           Ein Kontur sch\"{a}tzendes Kalmanfilter mithilfe der Evidenztheorie                         - Ohl, Sebastian; Maurer, M. )
                
        From Duplicate 1 (                           Ein Kontur sch\"{a}tzendes Kalmanfilter mithilfe der Evidenztheorie                         - Ohl, Sebastian; Maurer, M. )
                
Coordinated Turn Model (Blackman und Popoli, 1999) mit einer Winkelgeschwindigkeit von w=0
Das Prozessmodell des Zustandsvektors x[k] zum diskreten Zeitpunkt k
        
Turningfunktion!
        
        
        
      },
author = {Ohl, Sebastian and Maurer, M.},
file = {:Users/paul/Dropbox/Promotion/Literatur/2011 - Ohl, Maurer - Ein Kontur sch\"{a}tzendes Kalmanfilter mithilfe der Evidenztheorie.pdf:pdf},
journal = {rzbl04.biblio.etc.tu-bs.de},
title = {{Ein Kontur sch\"{a}tzendes Kalmanfilter mithilfe der Evidenztheorie}},
url = {http://rzbl04.biblio.etc.tu-bs.de:8080/docportal/servlets/MCRFileNodeServlet/DocPortal\_derivate\_00018867/Ohl-Kontur-schaetzende-Kalmanfilter.pdf},
year = {2011}
}
@inproceedings{Fuerstenberg2003,
author = {Fuerstenberg, Kay and Lages, Ulrich},
booktitle = {9th EAEC International Congress},
file = {:Users/paul/Dropbox/Promotion/Literatur/2003 - Fuerstenberg, Lages - Pedestrian detection and classification by laserscanners.pdf:pdf},
keywords = {active safety,classification,laserscanner,obstacle detection,pedestrian,pedestrian detection,pedestrian protection,recognition,tracking},
pages = {1--8},
title = {{Pedestrian detection and classification by laserscanners}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Pedestrian+Detection+and+Classification+by+Laserscanners\#0},
year = {2003}
}
@phdthesis{Hofmann2004,
author = {Hofmann, Ulrich},
file = {:Users/paul/Dropbox/Promotion/Literatur/2004 - Hofmann - Zur visuellen Umfeldwahrnehmung autonomer Fahrzeuge.pdf:pdf},
school = {Universit\"{a}t der Bundeswehr M\"{u}nchen},
title = {{Zur visuellen Umfeldwahrnehmung autonomer Fahrzeuge}},
url = {http://ub.unibw-muenchen.de/dissertationen/ediss/hofmann-ulrich/meta.html},
year = {2004}
}
@phdthesis{Weiss2011,
author = {Weiss, Thorsten},
file = {:Users/paul/Dropbox/Promotion/Literatur/2011 - Weiss - Hochgenaue Positionierung und Kartographie mit Laserscannern fu??r Fahrerassistenzsysteme.pdf:pdf},
school = {Universit\"{a}t Ulm},
title = {{Hochgenaue Positionierung und Kartographie mit Laserscannern fu??r Fahrerassistenzsysteme}},
url = {http://d-nb.info/1012989682/},
year = {2011}
}
@book{LaValle2006,
address = {Cambridge},
author = {LaValle, Steven M.},
doi = {10.1017/CBO9780511546877},
file = {:Users/paul/Dropbox/Promotion/Literatur/2006 - LaValle - Planning Algorithms.pdf:pdf},
isbn = {9780511546877},
publisher = {Cambridge University Press},
title = {{Planning Algorithms}},
url = {http://ebooks.cambridge.org/ref/id/CBO9780511546877},
year = {2006}
}
@article{Shibuhisa2007,
author = {Shibuhisa, Nao and Sato, Junji and Takahashi, T},
doi = {10.1109/IVS.2007.4290243},
file = {:Users/paul/Dropbox/Promotion/Literatur/2007 - Shibuhisa, Sato, Takahashi - Accurate vehicle localization using DTW between range data map and laser scanner data sequences.pdf:pdf},
isbn = {1-4244-1067-3},
issn = {1931-0587},
journal = {Intelligent Vehicles \ldots},
month = jun,
pages = {975--980},
publisher = {Ieee},
title = {{Accurate vehicle localization using DTW between range data map and laser scanner data sequences}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4290243 http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4290243},
year = {2007}
}
@phdthesis{Stuker2004,
abstract = {Im Rahmen der Arbeit wird auf konkrete Modifikationsm?? Uberholman?? ur variable Beobachtbarkeit von Zustandsgr?? Filter-Architektur eingegangen, umdieObjektverfolgung insbesondere beimWechsel der Perspektive ??? wie sie beispielsweise bei ?? oglichkeiten einer Kalman- overn auftritt ??? zu stabilisie- ren. Die Vorteile der vorgestellten Algorithmen werden anhand von realen Messdaten demonstriert. onnen die Vorteile von Radarsensoren bei der Bestimmung der dynamischen ur eine optimale Fusion sind jedoch uberblick drei behandelt werden: Die Verarbeitung asynchroner ur optische Sensoren und o\ss en.},
author = {St\"{u}ker, D},
booktitle = {Carl von Ossietzky-Universit\"{a}t},
file = {:Users/paul/Dropbox/Promotion/Literatur/2004 - St\"{u}ker - Heterogene Sensordatenfusion zur robusten Objektverfolgung im automobilen Stra\ss enverkehr.pdf:pdf},
number = {November 2003},
school = {Carl von Ossietzky-Universit\"{a}t Oldenburg},
title = {{Heterogene Sensordatenfusion zur robusten Objektverfolgung im automobilen Stra\ss enverkehr}},
url = {http://d-nb.info/972494464/34},
year = {2004}
}
@article{Manduchi2005,
author = {Manduchi, R and Castano, A and Talukder, A and Matthies, L},
file = {:Users/paul/Dropbox/Promotion/Literatur/2005 - Manduchi et al. - Obstacle Detection and Terrain Classification for Autonomous Off-Road Navigation.pdf:pdf},
journal = {Jet Propulsion},
keywords = {autonomous,color classification,ladar classification,obstacle detection,terrain classification},
pages = {81--102},
title = {{Obstacle Detection and Terrain Classification for Autonomous Off-Road Navigation}},
year = {2005}
}
@article{Thrun2000a,
author = {Thrun, Sebastian and Burgard, W},
file = {:Users/paul/Dropbox/Promotion/Literatur/2000 - Thrun, Burgard - A real-time algorithm for mobile robot mapping with applications to multi-robot and 3D mapping.pdf:pdf},
journal = {Robotics and Automation, 2000.},
number = {April},
title = {{A real-time algorithm for mobile robot mapping with applications to multi-robot and 3D mapping}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=844077},
year = {2000}
}
@phdthesis{Rosenberg2006,
author = {von Rosenberg, Harald},
file = {:Users/paul/Dropbox/Promotion/Literatur/2006 - Rosenberg - Sensorfusion zur Navigation eines Fahrzeugs mit low-cost Inertialsensorik.pdf:pdf},
school = {Universit\"{a}t Stuttgart},
title = {{Sensorfusion zur Navigation eines Fahrzeugs mit low-cost Inertialsensorik}},
type = {Diplomarbeit},
year = {2006}
}
@article{Caraffi2007,
author = {Caraffi, Claudio and Cattani, Stefano and Grisleri, Paolo},
doi = {10.1109/TITS.2007.908583},
file = {:Users/paul/Dropbox/Promotion/Literatur/2007 - Caraffi, Cattani, Grisleri - Off-Road Path and Obstacle Detection Using Decision Networks and Stereo Vision.pdf:pdf},
issn = {1524-9050},
journal = {IEEE Transactions on Intelligent Transportation Systems},
month = dec,
number = {4},
pages = {607--618},
title = {{Off-Road Path and Obstacle Detection Using Decision Networks and Stereo Vision}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4382936},
volume = {8},
year = {2007}
}
@article{Scaramuzza2007,
author = {Scaramuzza, Davide and Harati, Ahad and Siegwart, Roland},
doi = {10.1109/IROS.2007.4399276},
file = {:Users/paul/Dropbox/Promotion/Literatur/2007 - Scaramuzza, Harati, Siegwart - Extrinsic self calibration of a camera and a 3D laser range finder from natural scenes.pdf:pdf},
isbn = {978-1-4244-0911-2},
journal = {2007 IEEE/RSJ International Conference on Intelligent Robots and Systems},
month = oct,
pages = {4164--4169},
publisher = {Ieee},
title = {{Extrinsic self calibration of a camera and a 3D laser range finder from natural scenes}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4399276},
year = {2007}
}
@article{Ragel2005,
abstract = { An autonomous underwater vehicle (AUV) can employ the inertial navigation system (INS) to determine its position. The measurement from the INS, which utilizes the accelerometers and gyroscopes, deteriorates with time due to the accumulation of errors in the sensors. To reduce the error growth in the INS, an external aiding source such as the DGPS or the differential GLONASS can be utilized. The loosely coupled system approach is usually implemented in integrating the information from the aiding source and the INS. The two main architectures in the loosely coupled systems are the forward Kalman filter (FKF) and the direct feedback Kalman (DKF) filters. In this paper we explore the possibility of using these techniques for an aided INS in the AUV application. The advantages and the disadvantages of using the FKF and the DKF are also discussed.},
author = {Ragel, B.A. and Farooq, M.},
doi = {10.1109/ICIF.2005.1591871},
isbn = {0-7803-9286-8},
journal = {2005 7th International Conference on Information Fusion},
keywords = {AUV,GPS,IMM,INS,Kalman},
title = {{Comparison of forward Vs. feedback Kalman filter for aided inertial navigation system}},
volume = {1},
year = {2005}
}
@article{Hoffman1991,
author = {Hoffman, Regis and Krotkov, Eric},
file = {:Users/paul/Dropbox/Promotion/Literatur/1991 - Hoffman, Krotkov - Rerception or Rugged Terrain for a Walking Robot True Confessions and New Directions.pdf:pdf},
journal = {IEEE International Conference on Intelligent Robots},
title = {{Rerception or Rugged Terrain for a Walking Robot: True Confessions and New Directions}},
year = {1991}
}
@article{Lu1997,
author = {Lu, Feng},
file = {:Users/paul/Dropbox/Promotion/Literatur/1997 - Lu - Robot pose estimation in unknown environments by matching 2D range scans.pdf:pdf},
journal = {Journal of intelligent \&amp; robotic systems},
keywords = {aligning scans,reference scan,robot pose estimation,rotation search},
pages = {249--275},
title = {{Robot pose estimation in unknown environments by matching 2D range scans}},
url = {http://www.springerlink.com/index/U145107T0JR55467.pdf},
year = {1997}
}
@article{Jaschke2002,
author = {Jaschke, KP},
file = {:Users/paul/Dropbox/Promotion/Literatur/2002 - Jaschke - Lenkregler f\"{u}r Fahrzeuge mit hoher Schwerpunktlage.pdf:pdf},
institution = {Braunschweig},
journal = {\ldots [www]. Information from< http://www. biblio. \ldots},
title = {{Lenkregler f\"{u}r Fahrzeuge mit hoher Schwerpunktlage}},
url = {http://rzbl68.biblio.etc.tu-bs.de:8080/docportal/servlets/MCRFileNodeServlet/DocPortal\_derivate\_00001329/Document.pdf},
year = {2002}
}
@article{Spero2002,
author = {Spero, D.J. and Jarvis, R.a.},
doi = {10.1109/ROMOCO.2002.1177142},
file = {:Users/paul/Dropbox/Promotion/Literatur/2002 - Spero, Jarvis - Path planning for a mobile robot in a rough terrain environment.pdf:pdf},
isbn = {83-7143-429-4},
journal = {Proceedings of the Third International Workshop on Robot Motion and Control, 2002. RoMoCo '02.},
pages = {417--422},
publisher = {Poznan Univ. Technol},
title = {{Path planning for a mobile robot in a rough terrain environment}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1177142},
year = {2002}
}
@article{Welch2001,
annote = {Gute Erkl\"{a}rung zu Kalman und EKF},
author = {Welch, Greg},
file = {:Users/paul/Dropbox/Promotion/Literatur/2001 - Welch - An introduction to the Kalman filter.pdf:pdf},
journal = {Design},
pages = {1--16},
title = {{An introduction to the Kalman filter}},
url = {http://www.mendeley.com/research/an-introduction-to-the-kalman-filter/},
year = {2001}
}
@article{Decker1986,
author = {Decker, BL},
file = {:Users/paul/Dropbox/Promotion/Literatur/1986 - Decker - World geodetic system 1984.pdf:pdf},
title = {{World geodetic system 1984}},
volume = {3},
year = {1986}
}
@article{Homm2010,
author = {Homm, Florian and Duda, Alexander and Kaempchen, Nico and Waldmann, Peter and Ardelt, Michael},
file = {:Users/paul/Dropbox/Promotion/Literatur/2010 - Homm et al. - Lidarbasierte Fahrstreifen-und Randbebauungserkennung mit Occupancy Grids f\"{u}r Spurhalte-und Spurwechselfunktionen.pdf:pdf},
journal = {Tagung Sicherheit \ldots},
keywords = {Fahrbahnranderkennung,Fahrstreifenerkennung,Laserscanner,Lidar,Occupancy Grid},
pages = {1--8},
title = {{Lidarbasierte Fahrstreifen-und Randbebauungserkennung mit Occupancy Grids f\"{u}r Spurhalte-und Spurwechselfunktionen}},
url = {http://www.ftm.mw.tum.de/uploads/media/20\_homm.pdf},
year = {2010}
}
@article{Euston2008,
author = {Euston, M. and Coote, P. and Mahony, R.},
doi = {10.1109/IROS.2008.4650766},
file = {:Users/paul/Dropbox/Promotion/Literatur/2008 - Euston, Coote, Mahony - A complementary filter for attitude estimation of a fixed-wing UAV.pdf:pdf},
isbn = {978-1-4244-2057-5},
journal = {Intelligent Robots and \ldots},
month = sep,
pages = {340--345},
publisher = {Ieee},
title = {{A complementary filter for attitude estimation of a fixed-wing UAV}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4650766 http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4650766},
year = {2008}
}
@article{Rusinkiewicz2001,
author = {Rusinkiewicz, S and Levoy, Marc},
file = {:Users/paul/Dropbox/Promotion/Literatur/2001 - Rusinkiewicz, Levoy - Efficient variants of the ICP algorithm(2).pdf:pdf},
journal = {3-D Digital Imaging and Modeling,},
title = {{Efficient variants of the ICP algorithm}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=924423},
year = {2001}
}
@article{Badino2007,
abstract = {We have presented a method for the computation of free space with stochastic occupancy grids. Three},
author = {Badino, H and Franke, Uwe},
file = {:Users/paul/Dropbox/Promotion/Literatur/2007 - Badino, Franke - Free space computation using stochastic occupancy grids and dynamic programming.pdf:pdf},
journal = {Workshop on Dynamical},
keywords = {free space,occupancy grid},
mendeley-tags = {free space,occupancy grid},
pages = {1--12},
title = {{Free space computation using stochastic occupancy grids and dynamic programming}},
url = {http://www.vsi.cs.uni-frankfurt.de/download/badino\_wdv2007.pdf},
year = {2007}
}
@article{Ye2002,
abstract = {This paper presents a characterization study of the Sick LMS 200 laser scanner. A number of parameters, such as operation time, data transfer rate, target surface proper- ties, as well as the incidence angle, which may potentially affect the sensing performance, are investigated. A prob- abilistic range measurement model is built based on the experimental results. The paper also analyzes the mixed pixels problem of the scanner.},
annote = {Beschreibung zum Testprozedure eines Laserscanners um z.B. ein Simulationsmodell eines Laserscanners zu erstellen
        
        
Other measurement errors are caused by target surface reflectance properties and the incidence angle of the laser beam. Maximal errors for most cases were on the order of 17 mm.},
author = {Ye, Cang and Borenstein, Johann},
file = {:Users/paul/Dropbox/Promotion/Literatur/2002 - Ye, Borenstein - Characterization of a 2-D Laser Scanner for Mobile Robot Obstacle Negotiation.pdf:pdf},
isbn = {0780372727},
journal = {International Conference on Robotics \& Automation},
keywords = {Charakterisierung,Laserscanner,eigenschaften,parameter},
number = {May},
pages = {2512--2518},
title = {{Characterization of a 2-D Laser Scanner for Mobile Robot Obstacle Negotiation}},
year = {2002}
}
@inproceedings{Brenneke2003,
author = {Brenneke, Christian and Wulf, Oliver and Wagner, Bernardo},
booktitle = {Intelligent Robots and Systems, 2003.(IROS 2003). Proceedings. 2003 IEEE/RSJ International Conference on},
file = {:Users/paul/Dropbox/Promotion/Literatur/2003 - Brenneke, Wulf, Wagner - Using 3d laser range data for slam in outdoor environments.pdf:pdf},
isbn = {0780378601},
number = {October},
pages = {188--193},
publisher = {IEEE},
title = {{Using 3d laser range data for slam in outdoor environments}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1250626},
volume = {1},
year = {2003}
}
@article{Hornung2013,
author = {Hornung, Armin and Wurm, Kai M. and Bennewitz, Maren and Stachniss, Cyrill and Burgard, Wolfram},
doi = {10.1007/s10514-012-9321-0},
file = {:Users/paul/Dropbox/Promotion/Literatur/2013 - Hornung et al. - OctoMap an efficient probabilistic 3D mapping framework based on octrees.pdf:pdf},
issn = {0929-5593},
journal = {Autonomous Robots},
keywords = {3d,although 3d mapping is,an integral component of,and efficient implementations,available,implemen-,many,mapping,navigation,probabilistic,reliable,robotic systems,the lack of such,there exist few readily},
month = feb,
number = {3},
pages = {189--206},
title = {{OctoMap: an efficient probabilistic 3D mapping framework based on octrees}},
url = {http://link.springer.com/10.1007/s10514-012-9321-0},
volume = {34},
year = {2013}
}
@article{Parra1999,
author = {Parra, Carlos and Murrieta-Cid, R and Devy, Michel},
file = {:Users/paul/Dropbox/Promotion/Literatur/1999 - Parra, Murrieta-Cid, Devy - 3-d modelling and robot localization from visual and range data in natural scenes.pdf:pdf},
journal = {Computer Vision Systems},
pages = {450--468},
title = {3-d modelling and robot localization from visual and range data in natural scenes},
url = {http://www.springerlink.com/index/akevce4am9ef1mey.pdf},
year = {1999}
}
@article{Cappelle2008,
author = {Cappelle, Cindy and Najjar, M El Badaoui El},
file = {:Users/paul/Dropbox/Promotion/Literatur/2008 - Cappelle, Najjar - Obstacle detection and localization method based on 3D model Distance validation with ladar.pdf:pdf},
isbn = {9781424416479},
journal = {, 2008. ICRA 2008.},
keywords = {Collision Avoidance,Computer Vision,Intelligent Transportation Systems},
pages = {4031--4036},
title = {{Obstacle detection and localization method based on 3D model: Distance validation with ladar}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4543830},
year = {2008}
}
@article{Wender2008,
author = {Wender, S. and Dietmayer, Klaus},
doi = {10.1049/iet-its},
file = {:Users/paul/Dropbox/Promotion/Literatur/2008 - Wender, Dietmayer - 3d vehicle detection using a laser scanner and a video camera.pdf:pdf},
journal = {Intelligent Transport Systems, IET},
number = {2},
pages = {105--112},
title = {3d vehicle detection using a laser scanner and a video camera},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4534342},
volume = {2},
year = {2008}
}
@article{Kingston2004,
address = {Reston, Virigina},
author = {Kingston, Derek and Beard, Randal},
doi = {10.2514/6.2004-6488},
file = {:Users/paul/Dropbox/Promotion/Literatur/2004 - Kingston, Beard - Real-Time Attitude and Position Estimation for Small UAVs Using Low-Cost Sensors.pdf:pdf},
isbn = {978-1-62410-081-9},
journal = {AIAA 3rd "Unmanned Unlimited" Technical Conference, Workshop and Exhibit},
month = sep,
pages = {1--9},
publisher = {American Institute of Aeronautics and Astronautics},
title = {{Real-Time Attitude and Position Estimation for Small UAVs Using Low-Cost Sensors}},
url = {http://arc.aiaa.org/doi/abs/10.2514/6.2004-6488},
year = {2004}
}
@article{Nagai2004,
abstract = {Three dimension data are in great demand for the various applications such as 3D GIS, navigation, digital archive, simulation, computer games, and so on. In order to represent space in details, it is indispensable to acquire 3D shape and texture together. However, there still lacks a reliable, quick, and handy method of acquiring three dimension data at higher resolution. In this research, we propose a combination of a digital camera and a small (cheap) laser scanner with inexpensive IMU (Inertial Measurement Unit) for unmanned air vehicles. 3D shape is acquired by laser scanner as point cloud data, and texture is acquired by CCD sensor from the same platform simultaneously. Positioning data is acquired by GPS (Global Positioning System) and IMU. All the sensors are synchronized with movement or attitude of the platform. In this paper, a method of integrating all the sensors is focused. All the sensors are tightly fixed on the platform to establish rigorous geometric relationships. Calibration of laser scanner and CCD camera is conducted to know relative position and attitude of each sensor against GPS and IMU. Through Kalman filter, an optimal estimate of the sensor position and attitude is estimated from GPS and IMU. Bundle block adjustment is conducted using continuous CCD images. The result of bundle block adjustment aids Kalman filter by initialization of position and attitude. Using this measurement system, a procedure for automated construction of digital surface model is developed using these sensors. This paper proposes a new method of rendering objects with rich shape and detailed texture. Sensor position and attitude for mapping are basically acquired by GPS/IMU and their errors are complemented by digital camera images using tie point. In case of real time mapping, colored point cloud model is produced as a quick view. Feature extraction is conducted by range data and image data. Geometric shape which is acquired by leaser scanner represent features. Texture information, which is acquired by digital camera, details those features. That is, more detailed extraction is possible using both 3D shapes and colors. It is possible to extract not only man-made object but also natural object such as people and vegetation.},
author = {Nagai, Masahiko and Shibasaki, Ryosuke and Manandhar, Dinesh and Zhao, Huijing},
file = {:Users/paul/Dropbox/Promotion/Literatur/2004 - Nagai et al. - DEVELOPMENT OF DIGITAL SURFACE MODEL AND FEATURE EXTRACTION BY INTEGRATING LASER SCANNER AND CCD SENSOR WITH IMU.pdf:pdf},
journal = {Camera},
keywords = {calibration,ccd,feature,imu,laser scanning,mobile,model,platform},
pages = {4--6},
title = {{DEVELOPMENT OF DIGITAL SURFACE MODEL AND FEATURE EXTRACTION BY INTEGRATING LASER SCANNER AND CCD SENSOR WITH IMU}},
url = {http://www.isprs.org/proceedings/XXXV/congress/comm5/papers/655.pdf},
volume = {Proceeding},
year = {2004}
}
@article{Kaempchen2004,
abstract = {In established driver assistance systems each application relies on its own sensor, which observes the vehicles environment. Advanced driver assistance systems (ADAS) have increasing demand for several sensor systems. The described Laserscanner and video based sensor fusion approach serves as a general platform for multiple active safety and comfort applications. A large field of view is obtained and the certainty and precision of the estimates in the relevant regions is increased significantly. Vehicle position measurements and classification, lane estimation as well as pedestrian recognition enable a broad support for applications such as Lane Departure Warning, Automatic Emergency Breaking, PreCrash, Pedestrian Protection, ACC Stop\&Go and Low Speed Following.},
author = {Kaempchen, Nico and Dietmayer, Klaus},
file = {:Users/paul/Dropbox/Promotion/Literatur/2004 - Kaempchen, Dietmayer - FUSION OF LASERSCANNER AND VIDEO FOR ADVANCED DRIVER ASSISTANCE SYSTEMS.pdf:pdf},
journal = {System},
pages = {1--8},
title = {{FUSION OF LASERSCANNER AND VIDEO FOR ADVANCED DRIVER ASSISTANCE SYSTEMS}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.58.7969\&rep=rep1\&type=pdf},
year = {2004}
}
@article{Gschwandtner2011,
author = {Gschwandtner, Michael and Kwitt, Roland and Uhl, Andreas and Pree, Wolfgang},
file = {:Users/paul/Dropbox/Promotion/Literatur/2011 - Gschwandtner et al. - BlenSor blender sensor simulation toolbox.pdf:pdf},
journal = {Advances in Visual Computing},
keywords = {Blensor},
mendeley-tags = {Blensor},
number = {Isvc},
pages = {199--208},
title = {{BlenSor: blender sensor simulation toolbox}},
url = {http://www.rkwitt.org/files/Gschwandtner11b.pdf http://link.springer.com/chapter/10.1007/978-3-642-24031-7\_20},
volume = {6939},
year = {2011}
}
@book{Cech2008,
author = {Cech, Markus},
booktitle = {Regelungstechnik},
file = {:Users/paul/Dropbox/Promotion/Literatur/2008 - Cech - Fahrspursch\"{a}tzung aus monokularen Bildfolgen f\"{u}r innerst\"{a}dtische Fahrerassistenzanwendungen.pdf:pdf},
isbn = {9783866443518},
number = {013},
publisher = {KIT Scientific Publishing},
title = {{Fahrspursch\"{a}tzung aus monokularen Bildfolgen f\"{u}r innerst\"{a}dtische Fahrerassistenzanwendungen}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=OxTt6KyMV3oC\&amp;oi=fnd\&amp;pg=PR9\&amp;dq=Fahrspursch?tzung+aus+monokularen+Bildfolgen+f?r+innerst?dtische+Fahrer-+assistenzanwendungen\&amp;ots=2pS1nMN2aq\&amp;sig=9rCQUyOsoyE8l8NaV8DRra7aWyM},
volume = {13},
year = {2008}
}
@article{Zhao2005,
abstract = {We propose a general framework for aligning continuous (oblique) video onto 3D sensor data. We align a point cloud computed from the video onto the point cloud directly obtained from a 3D sensor. This is in contrast to existing techniques where the 2D images are aligned to a 3D model derived from the 3D sensor data. Using point clouds enables the alignment for scenes full of objects that are difficult to model; for example, trees. To compute 3D point clouds from video, motion stereo is used along with a state-of-the-art algorithm for camera pose estimation. Our experiments with real data demonstrate the advantages of the proposed registration algorithm for texturing models in large-scale semiurban environments. The capability to align video before a 3D model is built from the 3D sensor data offers new practical opportunities for 3D modeling. We introduce a novel modeling-through-registration approach that fuses 3D information from both the 3D sensor and the video. Initial experiments with real data illustrate the potential of the proposed approach.},
author = {Zhao, Wenyi and Nister, David},
doi = {10.1109/TPAMI.2005.152},
file = {:Users/paul/Dropbox/Promotion/Literatur/2005 - Zhao, Nister - Alignment of continuous video onto 3D point clouds.pdf:pdf},
issn = {0162-8828},
journal = {Pattern Analysis and Machine},
keywords = {Algorithms,Artificial Intelligence,Automated,Automated: methods,Cluster Analysis,Computer-Assisted,Computer-Assisted: methods,Image Enhancement,Image Enhancement: methods,Image Interpretation,Imaging,Information Storage and Retrieval,Information Storage and Retrieval: methods,Pattern Recognition,Photogrammetry,Photogrammetry: methods,Subtraction Technique,Three-Dimensional,Three-Dimensional: methods,Video Recording,Video Recording: methods},
month = aug,
number = {8},
pages = {1305--18},
pmid = {16119268},
title = {{Alignment of continuous video onto 3D point clouds}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16119268 http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1453517},
volume = {27},
year = {2005}
}
@article{Milella2006,
author = {Milella, a.},
doi = {10.1109/ICVS.2006.56},
file = {:Users/paul/Dropbox/Promotion/Literatur/2006 - Milella - Stereo-based ego-motion estimation using pixel tracking and iterative closest point.pdf:pdf},
isbn = {0-7695-2506-7},
journal = {Vision Systems, 2006 ICVS'06. IEEE},
number = {Icvs},
pages = {21--21},
publisher = {Ieee},
title = {{Stereo-based ego-motion estimation using pixel tracking and iterative closest point}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1578709 http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1578709},
year = {2006}
}
@article{Fuerstenberg2003a,
abstract = {This paper presents innovations for detection of obstacles and road using a Multilayer Laserscanner. The classification of pedestrians and other road users require robust object tracking algorithms. Their reliability strongly depends on a precise ego-motion compensation. A new method of ego-motion estimation based on relative velocities of tracked objects will be introduced. This method operates especially under undefined driving conditions, such as skidding of the ego vehicle, where algorithms based on the vehicle???s INS data fail.},
annote = {Road Detection with Non-Linear Filtering},
author = {Fuerstenberg, Kay and Dietmayer, Klaus and Lages, Ulrich},
file = {:Users/paul/Dropbox/Promotion/Literatur/2003 - Fuerstenberg, Dietmayer, Lages - Laserscanner Innovations for Detection of Obstacles and Road Multilayer Laserscanner Ego-Motion.pdf:pdf},
keywords = {classification,ego-motion,laserscanner,obstacle detection,pedestrian recognition,road,tracking},
pages = {1--17},
title = {{Laserscanner Innovations for Detection of Obstacles and Road Multilayer Laserscanner Ego-Motion Estimation}},
year = {2003}
}
@article{Fuerstenberg2004,
author = {Fuerstenberg, Kay and Dietmayer, Klaus},
file = {:Users/paul/Dropbox/Promotion/Literatur/2004 - Fuerstenberg, Dietmayer - Fahrzeugumfeldsensierung mit mehrzeiligen Laserscannern.pdf:pdf},
journal = {Sensoren und},
title = {{Fahrzeugumfeldsensierung mit mehrzeiligen Laserscannern}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Fahrzeugumfeldsensierung+mit+mehrzeiligen+Laserscannern\#0},
year = {2004}
}
@article{Zask2009,
abstract = {In this paper, we present a simple and efficient incremental algorithmfor 3D modeling amenable to real- time implementation. The algorithm creates a texture-mapped polygonal mesh model of the environment from a monocular video feed or sequence of images.},
author = {Zask, Ran and Dailey, Matthew N.},
doi = {10.1109/ECTICON.2009.5137138},
file = {:Users/paul/Dropbox/Promotion/Literatur/2009 - Zask, Dailey - Rapid 3D visualization of indoor scenes using 3D occupancy grid isosurfaces.pdf:pdf},
isbn = {978-1-4244-3387-2},
journal = {2009 6th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology},
month = may,
pages = {672--675},
publisher = {Ieee},
title = {{Rapid 3D visualization of indoor scenes using 3D occupancy grid isosurfaces}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5137138},
year = {2009}
}
@phdthesis{Lu1995,
author = {Lu, Feng},
file = {:Users/paul/Dropbox/Promotion/Literatur/1995 - Lu - Shape registration using optimization for mobile robot navigation.pdf:pdf},
school = {University of Toronto},
title = {{Shape registration using optimization for mobile robot navigation}},
url = {http://web.cs.dal.ca/~eem/cvWeb/pubs/LUFENG\_THESIS.pdf},
year = {1995}
}
@book{Christensen1999,
abstract = {This paper concerns the exploration of a natural environment by a mobile robot equipped with both a video camera and a range sensor (stereo or laser range finder); we focus on the interest of such a multisensory system to deal with the incremental construction of a global model of the environment and with the 3-D localization of the mobile robot. The 3-D segmentation of the range data provides a geometrical scene description: the regions issued from the segmentation step correspond either to the ground or to objects emerging from this ground (e.g.rocks, vegetations). The 3D boundaries of these regions can be projected on the video image, so that each one can be characterized and afterwards identified, by a probabilistic method, to obtain its nature (e.g.soil, rocks...); the ground region can be over-segmented, adding visual information, such as the texture. During the robot motions, a slow and a fast processes are simultaneously executed; in the modelling process (currently 0.1Hz), a global landmark-based model is incrementally built and the robot situation can be estimated if some discriminant landmarks are selected from the detected objects in the range data; in the tracking process (currently 1Hz), selected landmarks are tracked in the visual data. The tracking results are used to simplify the matching between landmarks in the modelling process.},
address = {Berlin, Heidelberg},
author = {Christensen, Henrik and Parra, Carlos and Murrieta-Cid, Rafael and Devy, Michel and Briot, Maurice},
doi = {10.1007/3-540-49256-9},
isbn = {978-3-540-65459-9},
keywords = {Computer Science},
month = sep,
pages = {450--468},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Computer Vision Systems}},
url = {http://www.springerlink.com/content/akevce4am9ef1mey/},
volume = {1542},
year = {1999}
}
@misc{Strarker2005,
author = {Str\"{a}rker, Thorsten and Baumann, Richard},
file = {:Users/paul/Dropbox/Promotion/Literatur/2005 - Str\"{a}rker, Baumann - M\"{a}heinrichtung.pdf:pdf},
number = {19},
pages = {1--15},
title = {{M\"{a}heinrichtung}},
url = {http://www.freepatentsonline.com/EP1606987.pdf},
volume = {1},
year = {2005}
}
@inproceedings{Wittmer2012,
abstract = {Im Rahmen des Projektes "Mensch-Maschine-Interaktion" an der HTW Dresden werden die Einsatzm\"{o}glichkeiten von Umgebungssensorik zur Ortung und Erkennung von Hindernissen sowie M\"{o}glichkeiten der Automatisierung bestimmter Prozesse zur Entlastung des Bedieners beim F\"{u}hren einer Maschine untersucht.},
address = {Dresden},
author = {Wittmer, Martin and Borkert, Raphael and Balzer, Paul},
booktitle = {Fachtagung Nutzfahrzeugtechnik und Hydraulik},
file = {:Users/paul/Dropbox/Promotion/Literatur/2012 - Wittmer, Borkert, Balzer - Hindernisortung, -erkennung und -umfahrung mit an Auslegern gef\"{u}hrten Arbeitsger\"{a}ten der Kommunaltec.pdf:pdf},
keywords = {Laserscanner,Lidar,laser range finder,laserscanner,occupancy Grid,surface reconstruction},
mendeley-tags = {Laserscanner,Lidar},
pages = {62--69},
publisher = {Hochschule f\"{u}r Technik und Wirtschaft Dresden},
title = {{Hindernisortung, -erkennung und -umfahrung mit an Auslegern gef\"{u}hrten Arbeitsger\"{a}ten der Kommunaltechnik: Aktueller Arbeitsstand zur Umfeldsensorik und Simulation}},
year = {2012}
}
@techreport{Ohl2011a,
author = {Ohl, Sebastian and H\"{a}usler, Katharina and Maurer, Markus and Holldorb, Christian},
file = {:Users/paul/Dropbox/Promotion/Literatur/2011 - Ohl et al. - Autonomes Fahren im Stra\ss enbetriebsdienst auf Autobahnen.pdf:pdf},
institution = {TU Braunschweig},
pages = {19},
title = {{Autonomes Fahren im Stra\ss enbetriebsdienst auf Autobahnen}},
year = {2011}
}
@article{Best1998,
abstract = {This paper presents a method for autonomously constructing a complete general purpose surface description (model) of an object. The models are constructed based on a large number of noisy range images from an essentially arbitrary set of viewpoints around the object. The resulting models consist of a set of parametric surface patches. Results of testing the model building algorithm on two synthetic test objects are also presented.},
author = {Best, Leland and Magee, Michael},
file = {:Users/paul/Dropbox/Promotion/Literatur/1998 - Best, Magee - Autonomous construction of three-dimensional models from range data.pdf:pdf},
journal = {Pattern recognition},
number = {2},
pages = {121--136},
title = {{Autonomous construction of three-dimensional models from range data}},
url = {http://www.sciencedirect.com/science/article/pii/S0031320397000137},
volume = {31},
year = {1998}
}
@article{Homm2010a,
author = {Homm, Florian and Kaempchen, Nico and Ota, Jeff},
file = {:Users/paul/Dropbox/Promotion/Literatur/2010 - Homm, Kaempchen, Ota - Efficient occupancy grid computation on the gpu with lidar and radar for road boundary detection.pdf:pdf},
isbn = {9781424478682},
journal = {Symposium (IV), 2010},
keywords = {Automated Vehicles,Driver Assistance Systems,Vehicle Environment Perception},
pages = {1006--1013},
title = {{Efficient occupancy grid computation on the gpu with lidar and radar for road boundary detection}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5548091},
year = {2010}
}
@article{Thrun2000,
annote = {        s...robot state
        b...belief
bt(st)...belief state at time t
        d...data
        o...observation
        a...action
        m...model of the world (z.B. map)},
author = {Thrun, Sebastian},
file = {:Users/paul/Dropbox/Promotion/Literatur/2000 - Thrun - Probabilistic algorithms in robotics.pdf:pdf},
journal = {Ai Magazine},
number = {4},
pages = {93--109},
title = {{Probabilistic algorithms in robotics}},
url = {http://www.aaai.org/ojs/index.php/aimagazine/article/viewArticle/1534},
volume = {21},
year = {2000}
}
@article{Low2004,
author = {Low, KL},
file = {:Users/paul/Dropbox/Promotion/Literatur/2004 - Low - Linear least-squares optimization for point-to-plane icp surface registration.pdf:pdf},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {February},
pages = {2--4},
title = {{Linear least-squares optimization for point-to-plane icp surface registration}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Linear+Least-Squares+Optimization+for+Point-to-Plane+ICP+Surface+Registration\#0 http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Linear+least-squares+optimization+for+point-to-plane+icp+surface+registration\#0},
year = {2004}
}
@article{Homm2011,
author = {Homm, Florian and Kaempchen, Nico},
file = {:Users/paul/Dropbox/Promotion/Literatur/2011 - Homm, Kaempchen - Fusion of laserscannner and video based lanemarking detection for robust lateral vehicle control and lane chang.pdf:pdf},
isbn = {9781457708916},
journal = {Vehicles Symposium (IV),},
number = {Iv},
pages = {969--974},
title = {{Fusion of laserscannner and video based lanemarking detection for robust lateral vehicle control and lane change maneuvers}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5940424},
year = {2011}
}
@article{Weiss2007,
abstract = {Detailed digital maps are of benefit for navigation systems and also for future driver assistant and safety applica- tions. The generation of detailed digital maps is an expensive and time-consuming process as there is much manual rework. In this work, algorithms for the automatic detection of traffic infrastructure objects are proposed. The accurate positions of lane markings, sidewalks, reflection posts and guardrails are determined automatically by a vertically and a horizontally mounted automotive laser scanner. The high position accuracy of the mapped traffic infrastructure objects allows for the rapid generation of up to date, accurate and detailed digital infrastructure maps with a cost efficient sensor setup and a low demand for manual rework.},
annote = {Koordinatentrafo von Sensor-->WGS84
        
AUTOMATIC MAPPING OF GUARDRAILS AND SIDEWALKS},
author = {Weiss, Thorsten},
file = {:Users/paul/Dropbox/Promotion/Literatur/2007 - Weiss - Automatic detection of traffic infrastructure objects for the rapid generation of detailed digital maps using laser scann.pdf:pdf},
isbn = {1424410681},
journal = {Intelligent Vehicles Symposium, 2007},
pages = {1271--1277},
title = {{Automatic detection of traffic infrastructure objects for the rapid generation of detailed digital maps using laser scanners}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4290293},
year = {2007}
}
@article{Barczyk2011,
abstract = {We introduce a magnetometer-plus-GPS aided inertial navigation system for a helicopter UAV. A nonlinear observer is required to estimate the navigation states, typically an Extended Kalman Filter (EKF). A novel approach is the invariant observer, a constructive design method applicable to systems possessing symmetries. We review the theory and design an invariant observer for our example. Using an invariant observer guarantees a simplified form of the nonlinear estimation error dynamics. These are stabilized using an adaptation of the Invariant EKF, a systematic approach to compute the gains of an invariant observer. The resulting design is successfully implemented and validated in experiment and shows an improvement in performance over a conventional EKF.},
author = {Barczyk, Martin and Lynch, Alan F.},
doi = {10.1109/CDC.2011.6160733},
isbn = {978-1-61284-799-3},
issn = {0743-1546},
journal = {IEEE Conference on Decision and Control and European Control Conference},
pages = {5389--5394},
title = {{Invariant Extended Kalman Filter design for a magnetometer-plus-GPS aided inertial navigation system}},
year = {2011}
}
@article{Behzad1992,
abstract = {In this letter we propose an algorithm that does not yield such incorrect results, and preserves the statistical poperties of the surface. The method is best suited tbr reconstruction of random stationary surfaces, sudl as rough terrain. It has applications in off-road autonomous land navigation.},
annote = {Besserer Algorithmus um tiefe Stellen hinter verdeckten Hindernissen zu berechnen als nur zwischen Scannerpunkten zu interpolieren},
author = {Behzad, Kamgar-Parsi and Narayanan, P.J. and Davis, Larry S.},
doi = {10.1016/0167-8655(92)90122-G},
file = {:Users/paul/Dropbox/Promotion/Literatur/1992 - Behzad, Narayanan, Davis - Surface reconstruction (of rough terrain) in range image shadows.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {range image,rough surlhce,shadow,surface reconstruction},
month = sep,
number = {9},
pages = {657--667},
title = {{Surface reconstruction (of rough terrain) in range image shadows}},
url = {http://linkinghub.elsevier.com/retrieve/pii/016786559290122G},
volume = {13},
year = {1992}
}
@article{Pommier2002,
author = {Pommier, Val\'{e}rie and Sabatier, Jocelyn and Lanusse, Patrick and Oustaloup, Alain},
doi = {10.1016/S0967-0661(01)00154-X},
file = {:Users/paul/Dropbox/Promotion/Literatur/2002 - Pommier et al. - Crone control of a nonlinear hydraulic actuator.pdf:pdf},
issn = {09670661},
journal = {Control Engineering Practice},
keywords = {control,crone,fractional robust,hydraulic actuator,linearization,nonlinear system,volterra series},
month = apr,
number = {4},
pages = {391--402},
title = {{Crone control of a nonlinear hydraulic actuator}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S096706610100154X},
volume = {10},
year = {2002}
}
@article{Brenner2012,
author = {Brenner, Claus and Hofmann, Sabine},
file = {:Users/paul/Dropbox/Promotion/Literatur/2012 - Brenner, Hofmann - Evaluation of automatically extracted landmarks for future driver assistance systems.pdf:pdf},
journal = {Advances in Spatial Data Handling and GIS},
keywords = {accuracy,extraction,lidar,mapping,matching,mobile laser scanning,navigation},
title = {{Evaluation of automatically extracted landmarks for future driver assistance systems}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-25926-5\_13},
volume = {38},
year = {2012}
}
@article{Sola2013,
annote = {sch\"{o}ne Grafiken!
Matlab Code
      },
author = {Sola, J},
file = {:Users/paul/Dropbox/Promotion/Literatur/2013 - Sola - Simulataneous localization and mapping with the extended Kalman filter.pdf:pdf},
title = {{Simulataneous localization and mapping with the extended Kalman filter}},
url = {http://www.joansola.eu/JoanSola/objectes/curs\_SLAM/SLAM2D/SLAM course.pdf},
year = {2013}
}
@article{Toledo-Moreo2007,
annote = {Hat alle Raddrehzahlen zur Verf\"{u}gung},
author = {Toledo-Moreo, R},
file = {:Users/paul/Dropbox/Promotion/Literatur/2007 - Toledo-Moreo - High-integrity IMM-EKF-based road vehicle navigation with low-cost GPSSBASINS.pdf:pdf},
journal = {Intelligent \ldots},
number = {3},
pages = {491--511},
title = {{High-integrity IMM-EKF-based road vehicle navigation with low-cost GPS/SBAS/INS}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4298913},
volume = {8},
year = {2007}
}
@phdthesis{Scholer2010,
annote = {3D-Occupancy Grid Map},
author = {Sch\"{o}ler, Florian Erwin},
booktitle = {iai.uni-bonn.de},
file = {:Users/paul/Dropbox/Promotion/Literatur/2010 - Sch\"{o}ler - Personentracking in 3D-Laserentfernungsdaten.pdf:pdf},
title = {{Personentracking in 3D-Laserentfernungsdaten}},
url = {http://www.iai.uni-bonn.de/~schoele/pubs/diplomarbeit\_florianschoeler/diplomarbeit\_florianschoeler.pdf},
year = {2010}
}
@phdthesis{Gschwandtner2013,
author = {Gschwandtner, Michael},
file = {:Users/paul/Dropbox/Promotion/Literatur/2013 - Gschwandtner - Support Framework for Obstacle Detection on Autonomous Trains.pdf:pdf},
number = {September},
school = {University of Salzburg},
title = {{Support Framework for Obstacle Detection on Autonomous Trains}},
url = {http://download.blensor.org/gschwandtner12b.pdf},
year = {2013}
}
@phdthesis{Zou2012,
abstract = {Im Rahmen dieser Arbeit werden am Anfang bestehende Ans\"{a}tze zur Freiraumerkennung im auto- mobilen Umfeld untersucht. Nach der Wiederholung von Grundlagen wird zwei Algorithmen zur Frei- raumbestimmung basierend auf einer zur Verf\"{u}gung gestellten Occupancy-Gridmap mit Frei-Evidenz in Matlab bzw. C++ entworfen. Zum Schluss werden die entwickelten Methoden mit den vorher gesam- melten Messdaten in Framework wxWavE \"{u}berpr\"{u}ft und eine Zusammenfassung wird ausgegeben.},
author = {Zou, Ruimin},
file = {:Users/paul/Dropbox/Promotion/Literatur/2012 - Zou - Free Space Detection Based On Occupancy Gridmaps.pdf:pdf},
keywords = {Advanced Driver Assistance System,Dynamic Programming,Free Space Computation,Occupancy Gridmap,Stereo Vision},
number = {April},
school = {Technische Universit\"{a}t Darmstadt},
title = {{Free Space Detection Based On Occupancy Gridmaps}},
url = {http://www.ias.informatik.tu-darmstadt.de/uploads/Theses/Zhou\_MScThesis\_2012.pdf},
year = {2012}
}
@article{Hu2003,
author = {Hu, Congwei and Chen, W and Chen, Yongqi and Liu, Dajie},
doi = {10.5081/jgps.2.1.42},
file = {:Users/paul/Dropbox/Promotion/Literatur/2003 - Hu et al. - Adaptive Kalman filtering for vehicle navigation.pdf:pdf},
issn = {14463156},
journal = {Journal of Global Positioning \ldots},
keywords = {adaptive filtering,cities,extracted and compared with,gps,of the trajectory are,real time positioning,the map data at,the same,then the turning points,vehicle navigation},
month = jun,
number = {1},
pages = {42--47},
title = {{Adaptive Kalman filtering for vehicle navigation}},
url = {http://www.gnss.com.au/JoGPS/v2n1/v2n1pF.pdf http://www.gmat.unsw.edu.au/wang/jgps/v2n1/v2n1pf.pdf},
volume = {2},
year = {2003}
}
@article{Labayrade2005,
author = {Labayrade, R and Royere, Cyril and Gruyer, Dominique and Aubert, Didier and El, Rapha and Lcpc, Livic Inrets},
file = {:Users/paul/Dropbox/Promotion/Literatur/2005 - Labayrade et al. - Cooperative fusion for multi-obstacles detection with use of stereovision and laser scanner.pdf:pdf},
journal = {Autonomous Robots},
keywords = {cooperative fusion,imperfect data management,laser scanner,multi-obstacles detection,real time performance,stereovision},
pages = {117--140},
title = {{Cooperative fusion for multi-obstacles detection with use of stereovision and laser scanner}},
url = {http://www.springerlink.com/index/L7871448N9177W40.pdf},
year = {2005}
}
@article{Schubert2011,
annote = {Motion Models:
CV Constant Velocity
CA Constant Acceleration
CTRV Constant Turn Rate and Velocity
CTRA Constant Turn Rate and Acceleration
CCA Constant Curvature and Acceleration
      },
author = {Schubert, Robin and Adam, Christian and Obst, Marcus and Mattern, Norman and Leonhardt, Veit and Wanielik, Gerd},
doi = {10.1109/IVS.2011.5940526},
file = {:Users/paul/Dropbox/Promotion/Literatur/2011 - Schubert et al. - Empirical evaluation of vehicular models for ego motion estimation.pdf:pdf},
isbn = {978-1-4577-0890-9},
journal = {2011 IEEE Intelligent Vehicles Symposium (IV)},
month = jun,
pages = {534--539},
publisher = {Ieee},
title = {{Empirical evaluation of vehicular models for ego motion estimation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5940526},
year = {2011}
}
@book{Thrun2005,
author = {Thrun, Sebastian and Burgard, W and Fox, D},
file = {:Users/paul/Dropbox/Promotion/Literatur/2005 - Thrun, Burgard, Fox - Probabilistic robotics.pdf:pdf},
pages = {1999--2000},
title = {{Probabilistic robotics}},
url = {http://www.lavoisier.fr/livre/notice.asp?ouvrage=1218883},
year = {2005}
}
@article{Groll1996,
author = {Gr\"{o}ll, L. and Janda, O.},
journal = {VDI-Berichte},
pages = {377--386},
title = {{Analytische Zug\"{a}nge f\"{u}r die bakengest\"{u}tzte Positionsbestimung automatisch gef\"{u}hrter Fahrzeuge}},
volume = {1282},
year = {1996}
}
@article{Kelly1994,
author = {Kelly, Alonzo},
file = {:Users/paul/Dropbox/Promotion/Literatur/1994 - Kelly - A 3D state space formulation of a navigation Kalman filter for autonomous vehicles.pdf:pdf},
number = {May},
title = {{A 3D state space formulation of a navigation Kalman filter for autonomous vehicles}},
url = {http://oai.dtic.mil/oai/oai?verb=getRecord\&metadataPrefix=html\&identifier=ADA282853},
year = {1994}
}
@article{Blume2008,
author = {Blume, H.},
file = {:Users/paul/Dropbox/Promotion/Literatur/2008 - Blume - Wahrscheinlichkeitsbasierte Methoden zur autonomen F\"{u}hrung von Fahrzeugen in unsicherer Umgebung. 2008.pdf:pdf},
journal = {URL http://edok01. tib. uni-hannover. de/edoks/e01dh08/569293340. pdf.???Abruf},
keywords = {"Lokalisation,Objektverfolgung,ReaktiveBahnplanung",WahrscheinlichkeitsbasierteBahnplanung},
number = {November 1975},
pages = {12--08},
title = {{Wahrscheinlichkeitsbasierte Methoden zur autonomen F\"{u}hrung von Fahrzeugen in unsicherer Umgebung. 2008}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Wahrscheinlichkeitsbasierte+Methoden+zur+autonomen+F?hrung+von+Fahrzeugen+in+unsicherer+Umgebung\#0},
year = {2008}
}
@article{Lobo2003,
author = {Lobo, J},
doi = {10.1016/S0921-8890(03)00011-3},
file = {:Users/paul/Dropbox/Promotion/Literatur/2003 - Lobo - World feature detection and mapping using stereovision and inertial sensors.pdf:pdf},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
keywords = {3d reconstruction,inertial sensors,outlier removal,sensor fusion,vision},
month = jul,
number = {1},
pages = {69--81},
title = {{World feature detection and mapping using stereovision and inertial sensors}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0921889003000113},
volume = {44},
year = {2003}
}
@phdthesis{Stiene2006,
abstract = {Objekterkennung spielt in verschiedensten Industrie- und Forschungsbereichen eine zen- trale Rolle. Einem mobilen Roboter soll sie beispielsweise erm?? nicht nur aufnehmen und sich in dieser bewegen zu k?? oglichen, seine Umwelt onnen, sondern diese zu interpre- tieren und mit ihr zu interagieren. Insbesondere ist konturbasierte Objekterkennung ein schon seit Mitte des letzten Jahrhunderts intensiv betriebenes Forschungsgebiet. Die dadurch entstandene Vielzahl der zur Verf?? che Extraktion der Objektkonturen aus Tiefenbildern motivieren diese Arbeit. Die Tiefenbilder werden mit Hilfe eines 3D-Laserscanners, der auf dem mobilen Ro- boter Kurt3D installiert ist, aufgenommen. Die Segmentierung der Tiefenbilder mittels adaptivem Schwellwertverfahren wird durch eine semantische Betrachtung der Messwer- te erleichtert. Diese entfernt Bodenpunkte im Tiefenbild und markiert Tiefenspr?? ugung stehenden Verfahren sowie die einfa- unge. Die aus dem segmentierten Tiefenbild extrahierten Konturen werden durch verschie- dene Merkmale beschrieben und mittels einer Support-Vector-Machine klassifiziert. Es werden geometrische Merkmale, Hu- und Zernike-Momente, die Curvature-Scale-Space- Repr?? eingesetzt. Die Performanz der Klassifizierer wird mit Hilfe der Receiver-Operating- Characteristics-Analyse untersucht.},
annote = {Fast nur Theorie, keine Beispiele und nur mal ne Auflistung von Deskriptoren etc.},
author = {Stiene, Stefan},
file = {:Users/paul/Dropbox/Promotion/Literatur/2006 - Stiene - Konturbasierte Objekterkennung aus Teifenbildern eines 3D-Laserscanners.pdf:pdf},
title = {{Konturbasierte Objekterkennung aus Teifenbildern eines 3D-Laserscanners}},
url = {http://kos.informatik.uni-osnabrueck.de/download/stefan\_masterthesis.pdf},
year = {2006}
}
@article{Gallego2009,
author = {Gallego, Nieves and Mocholi, Antonio and Menendez, Miguel and Barrales, Raymundo},
doi = {10.1109/CERMA.2009.11},
file = {:Users/paul/Dropbox/Promotion/Literatur/2009 - Gallego et al. - Traffic Monitoring Improving Road Safety Using a Laser Scanner Sensor.pdf:pdf},
isbn = {978-0-7695-3799-3},
journal = {2009 Electronics, Robotics and Automotive Mechanics Conference (CERMA)},
keywords = {-intelligent sensors,detection sys-,intelligent transportation systems,laser scanner,tem,traffic parameters},
month = sep,
pages = {281--286},
publisher = {Ieee},
title = {{Traffic Monitoring: Improving Road Safety Using a Laser Scanner Sensor}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5341976},
year = {2009}
}
@misc{Buchholz2013,
annote = {Kennwort: "dummy"},
author = {Buchholz, J\"{o}rg J.},
file = {:Users/paul/Dropbox/Promotion/Literatur/2013 - Buchholz - Vorlesungsmanuskript Regelungstechnik und Flugregler.pdf:pdf},
publisher = {GRIN Verlag},
title = {{Vorlesungsmanuskript Regelungstechnik und Flugregler}},
url = {http://www.grin.com/de/e-book/82818/regelungstechnik-und-flugregler},
year = {2013}
}
@article{Mauch2011,
author = {Mauch, S.},
file = {:Users/paul/Dropbox/Promotion/Literatur/2011 - Mauch - Einf\"{u}hrung in den Kalman-Filter von Steffen Mauch.pdf:pdf},
journal = {Matrix},
pages = {11--15},
title = {{Einf\"{u}hrung in den Kalman-Filter von Steffen Mauch}},
year = {2011}
}
@article{Gordon2008,
abstract = {Die vorliegende Dissertation befasst sich auf vielschichtige Weise mit Genauigkeitsuntersuchungen terrestrischer Laserscanner.},
author = {Gordon, Bianca},
file = {:Users/paul/Dropbox/Promotion/Literatur/2008 - Gordon - Zur Bestimmung von Messunsicherheiten terrestrischer Laserscanner.pdf:pdf},
title = {{Zur Bestimmung von Messunsicherheiten terrestrischer Laserscanner}},
url = {http://tuprints.ulb.tu-darmstadt.de/1206/},
year = {2008}
}
@article{Weiss2008,
abstract = {Viele Komfort- und Sicherheitsapplikationen ben\"{o}tigen eine pr\"{a}zise Information \"{u}ber die Eigenbewegung des Fahrzeugs. Aus den Daten von serienm\"{a}\ss ig in heutigen Fahrzeugen verbauten Sensoren kann die Eigenbewegung bestimmt werden. Im Rahmen dieser Arbeit werden Algorithmen vorgestellt, die die Genauigkeit der Eigenbewegungsbestimmung mit Hilfe eines Laserscanners verbessern. Ein rasterbasierter und ein merkmalsbasierter SLAM Algorithmus f\"{u}r den robusten Einsatz im realen Stra\ss enverkehr erlaubt die pr\"{a}zise Eigenbewegungsbestimmung in Innenstadt-, Landstra\ss en und Autobahnszenarien und auch in extremen Fahrman\"{o}vern wie Schleudern oder Drift.},
author = {Weiss, Thorsten},
doi = {10.1524/auto.2008.0739},
file = {:Users/paul/Dropbox/Promotion/Literatur/2008 - Weiss - Positionierung eines Fahrzeugs in unbekannten Gebieten mit Hilfe von Laserscannern.pdf:pdf},
journal = {Integration The Vlsi Journal},
keywords = {laser scanner,movement estimation,online map,skidding,slam},
pages = {554--562},
title = {{Positionierung eines Fahrzeugs in unbekannten Gebieten mit Hilfe von Laserscannern}},
url = {http://www.oldenbourg-link.com/doi/pdf/10.1524/auto.2008.0739},
volume = {56},
year = {2008}
}
@phdthesis{Rusu2009,
author = {Rusu, Radu Bogdan},
booktitle = {Articial Intelligence (KI-Kuenstliche Intelligenz)\$\backslash\$},
file = {:Users/paul/Dropbox/Promotion/Literatur/2009 - Rusu - Semantic 3D object maps for everyday manipulation in human living environments.pdf:pdf},
publisher = {Springer},
school = {TU M\"{u}nchen},
title = {{Semantic 3D object maps for everyday manipulation in human living environments}},
url = {http://files.rbrusu.com/publications/RusuPhDThesis.pdf},
year = {2009}
}
@article{Davison2004,
abstract = {The performance of single-camera SLAM is improved when wide-angle optics provide a field of view greater than the 40 to 50 degrees lenses normally used in computer vision. The issue is one of feature contact: each landmark object mapped remains visible through a larger range of camera motion, meaning that feature density can be reduced and camera movement range can be increased. Further, localisation stability is improved since features at widely differing viewing angles are simultaneously visible. We present the first real-time (30 frames per second), fully automatic implementation of 3D SLAM using a hand-waved wide-angle camera, and demonstrate significant advances in the range and agility of motions which can be tracked over previous narrow field-of-view implementations.},
author = {Davison, A J and Cid, Y G and Kita, N},
doi = {10.1.1.60.9239},
journal = {Proc IFAC Symposium on Intelligent Autonomous Vehicles Lisbon},
keywords = {real time,slam,wide angle vision},
publisher = {Citeseer},
title = {{Real-Time 3D SLAM with wide-angle vision}},
url = {http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=pubmed\&cmd=Retrieve\&dopt=AbstractPlus\&list\_uids=4445800112434586313related:ySIOvKWnsj0J},
year = {2004}
}
@phdthesis{Schubert2006,
author = {Schubert, Robin},
file = {:Users/paul/Dropbox/Promotion/Literatur/2006 - Schubert - Automatische Bahnplanung und Hindernisumfahrung f\"{u}r ein autonom navigierendes Fahrzeug.pdf:pdf},
number = {August},
title = {{Automatische Bahnplanung und Hindernisumfahrung f\"{u}r ein autonom navigierendes Fahrzeug}},
year = {2006}
}
@article{Bellucci2010,
author = {Bellucci, Patrizia and Cipriani, Ernesto},
doi = {10.1007/s12544-010-0039-9},
file = {:Users/paul/Dropbox/Promotion/Literatur/2010 - Bellucci, Cipriani - Data accuracy on automatic traffic counting the SMART project results.pdf:pdf},
issn = {1867-0717},
journal = {European Transport Research Review},
keywords = {1108,70,accuracy,agencies have,measurement,n,providing an estimate of,roads,so far italian road,the importance and,traffic monitoring devices,usage of main national,validation procedure},
month = oct,
number = {4},
pages = {175--187},
title = {{Data accuracy on automatic traffic counting: the SMART project results}},
url = {http://www.springerlink.com/index/10.1007/s12544-010-0039-9},
volume = {2},
year = {2010}
}
@article{Elfes1989,
author = {Elfes, Alberto},
doi = {10.1109/2.30720},
file = {:Users/paul/Dropbox/Promotion/Literatur/1989 - Elfes - Using occupancy grids for mobile robot perception and navigation.pdf:pdf},
issn = {0018-9162},
journal = {Computer},
month = jun,
number = {6},
pages = {46--57},
title = {{Using occupancy grids for mobile robot perception and navigation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=30720},
volume = {22},
year = {1989}
}
@article{Manandhar2001,
abstract = {Laser mapping has become quite popular in recent days due to its capability of providing information directly in three dimensions. Three dimension data are used in many applications, like navigation, urban planning and management, utilities planning, virtual reality, computer games etc. However, there still lacks a reliable and quick method of acquiring three dimension data of the urban area at higher resolution. Most of the vehicle-borne systems developed so far are based on stereo photographs as the main source of data. In order to overcome the problem of acquiring three dimension data in urban area reliably, quickly and at high resolution, we have developed a vehicle- borne laser mapping system (VLMS). The system is equipped with laser scanners and line cameras for data acquisition. The system will assist in building 3-D GIS database of urban areas. In this paper we focus our discuss on feature extraction of such a system including it???s capabilities and limitations. In an urban area we encounter many different types of features like buildings, roads, utility facilities, trees and many others. Our discussions will be basically limited to the extraction of road surface, building faces, poles, trees, tunnel and some other features on the ground. We believe that this type of mobile mapping system will provide complimentary data to the existing photogrammetry method for the generation of more accurate 3-D data of urban environment.},
author = {Manandhar, Dinesh and Shibasaki, Ryosuke},
file = {:Users/paul/Dropbox/Promotion/Literatur/2001 - Manandhar, Shibasaki - FEATURE EXTRACTION FROM RANGE DATA.pdf:pdf},
journal = {Asian Conference on Remote Sensing},
keywords = {3-d gis,feature extraction,laser scanning,mobile mapping},
number = {November},
pages = {5--9},
title = {{FEATURE EXTRACTION FROM RANGE DATA}},
year = {2001}
}
@inproceedings{Wulf2003,
author = {Wulf, Oliver and Wagner, Bernardo},
booktitle = {International conference on control systems and computer science (CSCS14)},
file = {:Users/paul/Dropbox/Promotion/Literatur/2003 - Wulf, Wagner - Fast 3D scanning methods for laser measurement systems.pdf:pdf},
keywords = {3d perception,data acquisition systems,laser range finder,lms},
number = {section 2},
pages = {2--5},
title = {{Fast 3D scanning methods for laser measurement systems}},
url = {http://lars.mec.ua.pt/public/LAR Projects/Laser3D/2009\_JoaoDias/Prot?tipo/Laser Range Finder/Papers/Wulf03-CSCS14.pdf},
year = {2003}
}
@article{Collado2006,
abstract = {In this paper the self-calibration system of the IVVI (Intel- ligent Vehicle based on Visual Information) project is pre- sented. It pretends to ease the process of installation in commercial vehicles. The system is able to self calibrate a stereo-vision system using only basic road infrastructure. Specifically, only a frame captured in a straight and plane stretch of a road with marked lanes is required. Road lines are extracted with the Hough Transform, and used as a calibration pattern. Then, a genetic algorithm finds the height, pitch and roll parameters of the vision system. The user must run this algorithm only once, unless the vision system is replaced or reinstalled in a different position.},
address = {Tokyo, Japan},
author = {Collado, JM and Hilario, Cristina},
file = {:Users/paul/Dropbox/Promotion/Literatur/2006 - Collado, Hilario - Self-calibration of an on-board stereo-vision system for driver assistance systems.pdf:pdf},
journal = {Intelligent Vehicles \ldots},
pages = {156--162},
title = {{Self-calibration of an on-board stereo-vision system for driver assistance systems}},
url = {http://www.uc3m.es/portal/page/portal/dpto\_ing\_sistemas\_automatica/investigacion/lab\_sist\_inteligentes/publications/iv06-b.pdf http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1689621},
volume = {2},
year = {2006}
}
@article{Naikal2009,
author = {Naikal, Nikhil and Kua, John and Chen, George},
file = {:Users/paul/Dropbox/Promotion/Literatur/2009 - Naikal, Kua, Chen - Image augmented laser scan matching for indoor dead reckoning.pdf:pdf},
isbn = {9781424438044},
journal = {Intelligent Robots and},
pages = {4134--4141},
title = {{Image augmented laser scan matching for indoor dead reckoning}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5354641},
year = {2009}
}
@article{Likhachev2005,
author = {Likhachev, Maxim and Ferguson, DI and Gordon, GJ},
file = {:Users/paul/Dropbox/Promotion/Literatur/2005 - Likhachev, Ferguson, Gordon - Anytime Dynamic A An Anytime, Replanning Algorithm.pdf:pdf},
journal = {ICAPS},
title = {{Anytime Dynamic A*: An Anytime, Replanning Algorithm.}},
url = {http://www.aaai.org/Papers/ICAPS/2005/ICAPS05-027.pdf},
year = {2005}
}
@article{Cai2011,
address = {London},
author = {Cai, Guowei and Chen, Ben M. and Lee, Tong Heng},
doi = {10.1007/978-0-85729-635-1},
file = {:Users/paul/Dropbox/Promotion/Literatur/2011 - Cai, Chen, Lee - Unmanned Rotorcraft Systems.pdf:pdf},
isbn = {978-0-85729-634-4},
pages = {23--35},
publisher = {Springer London},
series = {Advances in Industrial Control},
title = {{Unmanned Rotorcraft Systems}},
url = {http://link.springer.com/10.1007/978-0-85729-635-1},
year = {2011}
}
@phdthesis{Schmid2012,
abstract = {Um den effizienten Einsatz von dreidimensionalen Karten zu erm\"{o}glichen wird ein Verfahren vorgestellt, mit dem sich der Detaillierungsgrad der Umgebungsmodellierung dynamisch und anwendungsgesteuert anpassen l\"{a}sst. Um},
annote = {Mit Vorsicht zu genie\ss en!!!
Ist von einem Managing Director von Robert Bosch, der die wahrscheinlich nur noch mal gemacht hat, um einen Titel zu bekommen.},
author = {Schmid, Matthias Roland},
file = {:Users/paul/Dropbox/Promotion/Literatur/2012 - Schmid - Umgebungserfassung fu??r Fahrerassistenzsysteme mit hierarchischen Belegungskarten.pdf:pdf},
number = {November},
pages = {205},
school = {Universit\"{a}t der Bundeswehr M\"{u}nchen},
title = {{Umgebungserfassung fu??r Fahrerassistenzsysteme mit hierarchischen Belegungskarten}},
url = {http://d-nb.info/1030485593/},
year = {2012}
}
@article{Kalman1960,
author = {Kalman, R E},
file = {:Users/paul/Dropbox/Promotion/Literatur/1960 - Kalman - A New Approach to Linear Filtering and Prediction Problems.pdf:pdf},
number = {Series D},
pages = {35--45},
title = {{A New Approach to Linear Filtering and Prediction Problems}},
url = {http://www.cs.unc.edu/~welch/kalman/media/pdf/Kalman1960.pdf},
volume = {82},
year = {1960}
}
@article{Kaempchen2005,
author = {Kaempchen, Nico and Buehler, Matthias},
file = {:Users/paul/Dropbox/Promotion/Literatur/2005 - Kaempchen, Buehler - Feature-level fusion for free-form object tracking using laserscanner and video.pdf:pdf},
journal = {2005. Proceedings. IEEE},
pages = {453--458},
title = {{Feature-level fusion for free-form object tracking using laserscanner and video}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1505145},
year = {2005}
}
@misc{Miller,
author = {Miller, Charlie and Valasek, Chris},
keywords = {CAN,Hack,OBD},
title = {{Adventures in Automotive Networks ans Control Units}},
url = {http://illmatics.com/car\_hacking.pdf},
urldate = {29/01/14}
}
@article{Tsai1987,
abstract = {A new technique for three-dimensional (3D) camera calibra- tion for machine vision metrology using off-the-shelf TV cameras and lenses is described. The two-stage technique is aimed at efficient computation of camera external position and orientation relative to object reference coordinate system as well as the effective focal length, radial lens distortion, and image scanning parameters. The two-stage technique has advantage in terms of accuracy, speed, and versatility over existing state of the art. A critical review of the state of the art is given in the beginning. A theoretical framework is established, supported by comprehensive proof in five appendixes, and may pave the way for future research on 3D robotics vision. Test results using real data are described. Both accuracy and speed are reported. The experimental results are analyzed and compared with theoretical prediction. Recent effort indi- cates that with slight modification, the two-stage calibration can be done in real time.},
author = {Tsai, Roger Y},
file = {:Users/paul/Dropbox/Promotion/Literatur/1987 - Tsai - A Versatile Camera Calibration Techniaue for High-Accuracy 3D Machine Vision Metrology Using Off-the-shelf TV Cameras and.pdf:pdf},
journal = {JOURNAL OF ROBOTICS AND AUTOMATION},
number = {4},
pages = {323--344},
title = {{A Versatile Camera Calibration Techniaue for High-Accuracy 3D Machine Vision Metrology Using Off-the-shelf TV Cameras and Lenses}},
year = {1987}
}
@article{Whitaker1998,
author = {Whitaker, RT},
file = {:Users/paul/Dropbox/Promotion/Literatur/1998 - Whitaker - A level-set approach to 3D reconstruction from range data.pdf:pdf},
journal = {International Journal of Computer Vision},
number = {3},
pages = {203--231},
title = {{A level-set approach to 3D reconstruction from range data}},
url = {http://dl.acm.org/citation.cfm?id=299682},
volume = {29},
year = {1998}
}
@phdthesis{Vacek2008,
author = {Vacek, S},
file = {:Users/paul/Dropbox/Promotion/Literatur/2008 - Vacek - Videogest\"{u}tzte Umfelderfassung zur Interpretation von Verkehrssituationen.pdf:pdf},
isbn = {9783866443501},
school = {Universit\"{a}t Karlsruhe},
title = {{Videogest\"{u}tzte Umfelderfassung zur Interpretation von Verkehrssituationen}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=5ERpGNAIGO0C\&amp;oi=fnd\&amp;pg=PR2\&amp;dq=Videogest?tzte+Umfelderfassung+zur+Interpretation+von+Verkehrssituationen\&amp;ots=JKtQHedCkY\&amp;sig=WjsCNJH8GHtuWZfb1n64Jds0Fnk},
year = {2008}
}
@book{JackB.Kuipers1999,
author = {{Jack B. Kuipers}},
file = {:Users/paul/Dropbox/Promotion/Literatur/1999 - Jack B. Kuipers - Quaternions and rotation sequences.pdf:pdf},
title = {{Quaternions and rotation sequences}},
url = {http://www.emis.ams.org/proceedings/Varna/vol1/GEOM09.pdf},
year = {1999}
}
@article{Ruland2010,
author = {Ruland, Thomas and Loose, Heidi and Pajdla, Tomas},
file = {:Users/paul/Dropbox/Promotion/Literatur/2010 - Ruland, Loose, Pajdla - Hand-eye autocalibration of camera positions on vehicles.pdf:pdf},
isbn = {9781424476596},
journal = {Systems (ITSC), 2010},
pages = {367--372},
title = {{Hand-eye autocalibration of camera positions on vehicles}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5625279},
year = {2010}
}
@inproceedings{Veichtlbauer2011,
author = {Veichtlbauer, Armin and Dorfinger, Peter and Schrittesser, Ulrich},
booktitle = {SENSORCOMM 2011, The Fifth International Conference on Sensor Technologies and Applications},
file = {:Users/paul/Dropbox/Promotion/Literatur/2011 - Veichtlbauer, Dorfinger, Schrittesser - Live Data Acquisition for Situation Awareness in Traffic Management Systems Using Laser S.pdf:pdf},
isbn = {9781612081441},
keywords = {-situation awareness,Situation Awareness,Vehicle Counting,aware-,compensate for a situation,hicle counting,however the knowledge of,sensor data acquisition,the current distribution of,these parameters does not,traffic management,ve-},
number = {c},
pages = {268--273},
title = {{Live Data Acquisition for Situation Awareness in Traffic Management Systems Using Laser Sensors}},
url = {http://www.thinkmind.org/index.php?view=article\&amp;articleid=sensorcomm\_2011\_11\_10\_10074},
year = {2011}
}
@article{Dunlay1988,
author = {Dunlay, Terry},
file = {:Users/paul/Dropbox/Promotion/Literatur/1988 - Dunlay - Obstacle avoidance perception processing for the autonomous land vehicle.pdf:pdf},
journal = {and Automation, 1988. Proceedings., 1988 IEEE},
pages = {912--917},
title = {{Obstacle avoidance perception processing for the autonomous land vehicle}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=12176},
year = {1988}
}
@phdthesis{Peters2010,
author = {Peters, Ole},
file = {:Users/paul/Dropbox/Promotion/Literatur/2010 - Peters - Kooperative F\"{u}hrung von Landmaschinen mittels Lidar.pdf:pdf},
school = {Halle-Wittenberg},
title = {{Kooperative F\"{u}hrung von Landmaschinen mittels Lidar}},
url = {http://books.google.de/books?id=\_XEpygAACAAJ},
year = {2010}
}
@phdthesis{Liu2009,
abstract = {Die vorliegende Arbeit beschreibt eine neuartige Objektverfolgung durch Fusion von Radar- und Monokameradaten auf Merkmalsebene. Diese Merkmale sind beim Radar der gemessene Radialabstand, die gemessene Radialgeschwindigkeit und der grob gesch\"{a}tzte Lateralwinkel eines Objekts vor dem Radar. Bei der Monokamera sind es der gemessene Lateralwinkel und die gemessene Breite eines Objekts im Bild. Da diese Merkmale durch das Messverfahren bedingt verrauscht sind, werden in dieser Arbeit zuerst statistische Fehlermodelle der beiden Sensoren analysiert und nachgebildet. Weiterhin wird ein fahr- zeugfestes, globales Koordinatensystem hergeleitet, um die Bewegung eines Objekts im Fahrzeugumfeld optimal zu beschreiben.},
author = {Liu, F.},
file = {:Users/paul/Dropbox/Promotion/Literatur/2009 - Liu - Objektverfolgung durch Fusion von Radar-und Monokameradaten auf Merkmalsebene f\"{u}r zuk\"{u}nftige Fahrerassistenzsysteme.pdf:pdf},
isbn = {9783866445772},
publisher = {KIT Scientific Publishing},
school = {Karlsruher Institut f\"{u}r Technologie},
title = {{Objektverfolgung durch Fusion von Radar-und Monokameradaten auf Merkmalsebene f\"{u}r zuk\"{u}nftige Fahrerassistenzsysteme}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=LqDj-cevqpEC\&amp;oi=fnd\&amp;pg=PR9\&amp;dq=Objektverfolgung+durch+Fusion+von+Radar-+und+Monokameradaten+auf+Merkmalsebene+f?r+zuk?nftige+Fahrerassistenzsysteme\&amp;ots=fTtAgDN2BB\&amp;sig=T\_X11CAr8eVfJxGtlIhmfGGczrk http://books.google.com/books?hl=en\&amp;lr=\&amp;id=LqDj-cevqpEC\&amp;oi=fnd\&amp;pg=PR9\&amp;dq=Objektverfolgung+durch+Fusion+von+Radar-+und+Monokameradaten+auf+Merkmalsebene+f?r+zuk?nftige+Fahrerassistenzsysteme\&amp;o},
year = {2009}
}
@article{Balzer2012,
address = {Dresden},
author = {Balzer, Paul},
journal = {HDS Journal},
pages = {21--22},
title = {{Fahrdynamik realistisch und anschaulich: Praktika mit einem Modellfahrzeug}},
url = {https://www.hds.uni-leipzig.de/fileadmin/media/HDS\_Journal\_1-2012\_Tagungsedition.pdf},
year = {2012}
}
@phdthesis{Mahlisch2009,
abstract = {Filter Synthesis for Simultaneous Minimization of Detection, Association, and State Uncertainties in Automotive Environment Perception with Heterogeneous Sensor Data},
author = {M\"{a}hlisch, M},
booktitle = {booksgooglecom},
file = {:Users/paul/Dropbox/Promotion/Literatur/2009 - M\"{a}hlisch - Filtersynthese zur simultanen Minimierung von Existenz-, Assoziations- und Zustandsunsicherheiten in der Fahrzeugumfe.pdf:pdf},
isbn = {3941543032},
pages = {224},
title = {{Filtersynthese zur simultanen Minimierung von Existenz-, Assoziations- und Zustandsunsicherheiten in der Fahrzeugumfelderfassung mit heterogenen Sensordaten}},
year = {2009}
}
@book{Szeliski2010,
author = {Szeliski, Richard},
file = {:Users/paul/Dropbox/Promotion/Literatur/2010 - Szeliski - Computer vision Algorithms and applications.pdf:pdf},
title = {{Computer vision: Algorithms and applications}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=bXzAlkODwa8C\&amp;oi=fnd\&amp;pg=PR9\&amp;dq=Computer+Vision+:+Algorithms+and+Applications\&amp;ots=gYZ872oECG\&amp;sig=7ywD1U2Xg1XOQWDY61QWiBAZN9w},
year = {2010}
}
@phdthesis{Kappeler2003,
abstract = {In der DaimlerChrysler Forschung gibt es ein System zur optischen Spurerkennung, das sich aus- schlie\ss lich an Fahrbahnmarkierungen orientiert. In dieser Arbeit wurde eine neue Spurerkennung entwickelt, die nur auf Positionen von Leitpfosten basiert. Dazu wurden verschiedene Bildverar- beitungsverfahren auf ihre Eignung zur Detektion der Leitpfosten in Kamerabildern und zu deren Verfolgung in Bildsequenzen untersucht. F\"{u}r die Spurpr\"{a}diktion wurde ein neues Stra\ss enmodell entwickelt. Dieses ist aus dem Modell einer ebenen Stra\ss e der bereits vorhandenen Spurerken- nung abgeleitet, um eine Fusion der Systeme zu erm\"{o}glichen. Die neue Spurpr\"{a}diktion, die sich an dreidimensionalen Leitpfostenpositionen orientiert, ber\"{u}cksichtigt zus\"{a}tzlich Steigungen und Gef\"{a}lle von Stra\ss en. II},
author = {K\"{a}ppeler, Uwe-Philipp},
file = {:Users/paul/Dropbox/Promotion/Literatur/2003 - K\"{a}ppeler - Erkennung und Verfolgung von Leitpfosten zur Spurpr\"{a}diktion.pdf:pdf},
number = {2073},
school = {Stuttgart},
title = {{Erkennung und Verfolgung von Leitpfosten zur Spurpr\"{a}diktion}},
url = {http://elib.uni-stuttgart.de/opus/volltexte/2003/1520/pdf/DIP-2073.pdf},
year = {2003}
}
@article{Sun2010,
abstract = {It is often crucial in most of today's Autonomous Underwater Vehicles (AUVs) missions that the vehicle position be known precisely. Navigation performance of an Aided Inertial Navigation System (AINS) is always limited by the accuracy of sensors. In this paper we focus on enhancing performance of the AINS via micronavigation, which exploits a so-called Displaced Phase Center Antenna (DPCA) technique. The method is tested on an AUV Synthetic Aperture Sonar (SAS) test platform and the experimental results validate the effectiveness of the approach developed. Effect of the bottom fluctuations on the micronavigation performance is also studied.},
author = {Sun, Feng Sun Feng and Xu, Wen Xu Wen and Li, Jianlong Li Jianlong},
doi = {10.1109/OCEANS.2010.5664097},
isbn = {978-1-4244-4332-1},
journal = {OCEANS 2010},
title = {{Enhancement of the Aided Inertial Navigation System for an AUV via micronavigation}},
year = {2010}
}
@book{Schmid1994,
annote = {Erste Betrachtungen zur Erkennung verdeckter Objekte unter Nutzung des 4D-Ansatzes},
author = {Schmid, M.},
file = {:Users/paul/Dropbox/Promotion/Literatur/1994 - Schmid - 3D-Erkennung von Fahrzeugen in Echtzeit aus monokularen Bildfolgen.pdf:pdf},
pages = {3--6},
publisher = {VDI-Verl. Dusseldorf},
title = {{3D-Erkennung von Fahrzeugen in Echtzeit aus monokularen Bildfolgen}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:3D-Erkennung+von+Fahrzeugen+in+Echtzeit+aus+monokularen+Bildfolgen\#0},
year = {1994}
}
@article{Kirchner2000,
author = {Kirchner, A},
file = {:Users/paul/Dropbox/Promotion/Literatur/2000 - Kirchner - Sensordatenverarbeitung eines Laserscanners fur autonome Fahrfunktionen von Kraftfahrzeugen.pdf:pdf},
journal = {FORTSCHRITT BERICHTE-VDI REIHE 12 \ldots},
title = {{Sensordatenverarbeitung eines Laserscanners fur autonome Fahrfunktionen von Kraftfahrzeugen}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Sensordatenverarbeitung+eines+Laserscanners+f?r+autonome+Fahrfunktionen+von+Kraftfahrzeugen\#0},
year = {2000}
}
@article{hart1972correction,
annote = {wahrscheinlich A* Ursprung!
        
      },
author = {Hart, Peter E and Nilsson, Nils J and Raphael, Bertram},
journal = {ACM SIGART Bulletin},
number = {37},
pages = {28--29},
publisher = {ACM},
title = {{Correction to a formal basis for the heuristic determination of minimum cost paths}},
year = {1972}
}
@article{Einhorn2011,
author = {Einhorn, E. and Schr\"{o}ter, Ch. and Gross, H.M.},
doi = {10.1016/j.robot.2011.02.008},
file = {:Users/paul/Dropbox/Promotion/Literatur/2011 - Einhorn, Schr\"{o}ter, Gross - Attention-driven monocular scene reconstruction for obstacle detection, robot navigation and map buil.pdf:pdf},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
month = may,
number = {5},
pages = {296--309},
publisher = {Elsevier B.V.},
title = {{Attention-driven monocular scene reconstruction for obstacle detection, robot navigation and map building}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0921889011000285},
volume = {59},
year = {2011}
}
@inproceedings{Liu2010,
author = {Liu, Mingyong and Lei, Xiaokang and Zhang, Siqi and Mu, Bingxian},
booktitle = {Robotics and Biomimetics (ROBIO), 2010 IEEE International Conference on},
file = {:Users/paul/Dropbox/Promotion/Literatur/2010 - Liu et al. - Natural landmark extraction in 2D laser data based on local curvature scale for mobile robot navigation.pdf:pdf},
isbn = {9781424493180},
pages = {525--530},
publisher = {IEEE},
title = {{Natural landmark extraction in 2D laser data based on local curvature scale for mobile robot navigation}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5723381},
year = {2010}
}
@article{Pathak2007,
author = {Pathak, Kaustubh and Birk, Andreas and Poppinga, Jann},
file = {:Users/paul/Dropbox/Promotion/Literatur/2007 - Pathak, Birk, Poppinga - 3d forward sensor modeling and application to occupancy grid based sensor fusion.pdf:pdf},
journal = {Intelligent Robots and},
title = {3d forward sensor modeling and application to occupancy grid based sensor fusion},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4399406},
volume = {2},
year = {2007}
}
@article{Spinello2008,
author = {Spinello, Luciano and Triebel, Rudolph},
doi = {10.1109/IROS.2008.4651109},
file = {:Users/paul/Dropbox/Promotion/Literatur/2008 - Spinello, Triebel - Multimodal detection and tracking of pedestrians in urban environments with explicit ground plane extraction.pdf:pdf},
isbn = {978-1-4244-2057-5},
journal = {Intelligent Robots and},
month = sep,
pages = {1823--1829},
publisher = {Ieee},
title = {{Multimodal detection and tracking of pedestrians in urban environments with explicit ground plane extraction}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4651109 http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4651109},
year = {2008}
}
@article{Veatch1990,
author = {Veatch, PA},
file = {:Users/paul/Dropbox/Promotion/Literatur/1990 - Veatch - Efficient algorithms for obstacle detection using range data.pdf:pdf},
journal = {Computer vision, Graphics, and image processing},
title = {{Efficient algorithms for obstacle detection using range data}},
url = {http://www.sciencedirect.com/science/article/pii/0734189X90900676},
year = {1990}
}
@inproceedings{El-Halawany2011,
author = {El-Halawany, S.I. and Lichti, D.D.},
booktitle = {Multi-Platform/Multi-Sensor Remote Sensing and Mapping (M2RSM), 2011 International Workshop on},
file = {:Users/paul/Dropbox/Promotion/Literatur/2011 - El-Halawany, Lichti - Detection of Road Poles from Mobile Terrestrial Laser Scanner Point Cloud.pdf:pdf},
isbn = {9781424494040},
keywords = {- road furniture,cylinder,eigenvalue,poles},
pages = {1--6},
publisher = {IEEE},
title = {{Detection of Road Poles from Mobile Terrestrial Laser Scanner Point Cloud}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5697364},
year = {2011}
}
@article{Brenner2009,
abstract = {Research and development of driver assistance systems is currently a very active field. One building block of future systems will be an accurate and reliable positioning, which can be realized by relative measurement, using on-board sensors and maps of the environment. However, a prerequisite will be that such maps can be produced fully automatically. This paper explores the use of dense laser scans from mobile laser scanning systems for the production of such maps. After presenting the problem and the matching approach, we introduce our test field which consists of a 22 km scan of roads, both inner city streets as well as highways. It is shown how suitable features can be extracted fully automatically. Finally, for a given trajectory, we evaluate how positioning will perform and draw conclusions regarding applicability and future work.},
author = {Brenner, Claus},
doi = {10.1007/978-3-642-00318-9},
isbn = {9783642003172},
journal = {Notes},
pages = {25--42},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Geoinformation and Cartography},
title = {{Extraction of Features from Mobile Laser Scanning Data for Future Driver Assistance Systems}},
url = {http://dx.doi.org/10.1007/978-3-642-00318-9\_2},
year = {2009}
}
@article{Sharif,
author = {Sharif, Massoud and Stein, A.},
file = {:Users/paul/Dropbox/Promotion/Literatur/2004 - Sharif, Stein - Integrated approach to predict confidence of GPS measurement.pdf:pdf},
journal = {isprsserv.ifp.uni-stuttgart.de},
keywords = {accuracy,acquisition,analysis,geodesy,gps,performance,surveying,transformation},
title = {{Integrated approach to predict confidence of GPS measurement}},
url = {http://isprsserv.ifp.uni-stuttgart.de/proceedings/XXXV/congress/comm3/papers/344.pdf},
year = {2004}
}
@article{Muller2009,
abstract = {In this paper we describe an object following system for ground robot mobility, which incorporates LIDAR-based object perception and model-based lane estimation into control signal generation. The},
author = {Muller, A and Manz, M and Himmelsbach, M.},
file = {:Users/paul/Dropbox/Promotion/Literatur/2009 - Muller, Manz, Himmelsbach - A model-based object following system.pdf:pdf},
isbn = {9781424435043},
journal = {Intelligent Vehicles},
pages = {242--249},
title = {{A model-based object following system}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5164285},
year = {2009}
}
@article{Bos2005,
annote = {Q, R, S Estimation
        
Measurement Covariance Matrix R
Process Noise Covariance Matrix Q
      },
author = {Bos, Robert and Bombois, Xavier and den Hof, PMJ Van},
file = {:Users/paul/Dropbox/Promotion/Literatur/2005 - Bos, Bombois, Hof - Designing a Kalman filter when no noise covariance information is available.pdf:pdf},
journal = {Proceedings of the 16th IFAC \ldots},
keywords = {kalman filter design,noise modelling,state estimation},
number = {2},
title = {{Designing a Kalman filter when no noise covariance information is available}},
url = {http://www.dcsc.tudelft.nl/~pvandenhof/Paperfiles/IFAC05-Bos\%26etal.pdf},
year = {2005}
}
@inproceedings{Irschara2009,
author = {Irschara, a. and Zach, C. and Frahm, J.-M. and Bischof, H.},
booktitle = {Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on},
doi = {10.1109/CVPR.2009.5206587},
file = {:Users/paul/Dropbox/Promotion/Literatur/2009 - Irschara et al. - From structure-from-motion point clouds to fast location recognition.pdf:pdf},
isbn = {978-1-4244-3992-8},
month = jun,
pages = {2599--2606},
publisher = {IEEE},
title = {{From structure-from-motion point clouds to fast location recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5206587 http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5206587},
year = {2009}
}
@phdthesis{Balzer2009a,
author = {Balzer, Paul},
file = {:Users/paul/Dropbox/Promotion/Literatur/2009 - Balzer - Wankstabilisierung einspuriger Fahrzeuge mittels traversierender Aktorik.pdf:pdf},
keywords = {Regelungstechnik,Reglerauslegung,State-Space},
number = {September},
title = {{Wankstabilisierung einspuriger Fahrzeuge mittels traversierender Aktorik}},
year = {2009}
}
@article{Ohl2011c,
author = {Ohl, Sebastian and Matthaei, Richard and M\"{u}ller, Matthias and Maurer, Markus},
file = {:Users/paul/Dropbox/Promotion/Literatur/2011 - Ohl et al. - Softwarearchitektur der gitterbasierten Sensordatenfusion des Projekts Stadtpilot.pdf:pdf},
journal = {rzbl04.biblio.etc.tu-bs.de},
title = {{Softwarearchitektur der gitterbasierten Sensordatenfusion des Projekts Stadtpilot}},
url = {http://rzbl04.biblio.etc.tu-bs.de/docportal/servlets/MCRFileNodeServlet/DocPortal\_derivate\_00018240/Ohl-Softwarearchitektur-Stadtpilot.pdf},
year = {2011}
}
@phdthesis{Prat2011,
annote = {viele Literaturstellen angegeben um historischen und inhaltlichen \"{U}berblick zu bekommen},
author = {Prat, Alvaro Catala},
file = {:Users/paul/Dropbox/Promotion/Literatur/2011 - Prat - Sensordatenfusion und Bildverarbeitung zur Objekt-und Gefahrenerkennung.pdf:pdf},
number = {November 2010},
school = {Technischen Universit\"{a}t Carolo-Wilhelmina zu Braunschweig},
title = {{Sensordatenfusion und Bildverarbeitung zur Objekt-und Gefahrenerkennung}},
url = {http://rzbl04.biblio.etc.tu-bs.de:8080/docportal/servlets/MCRFileNodeServlet/DocPortal\_derivate\_00018702/Dissertation.pdf},
year = {2011}
}
@phdthesis{Ohl2011,
abstract = {In dieser Arbeit wurde ein System zur Wahrnehmung des Fahrzeugumfeldes im urbanen Gebiet entwickelt. Dieses wird im Rahmen des DARPA Urban Challenge von dem Team CarOLO eingesetzt. Die DARPA Urban Challenge ist ein Wettbewerb f\"{u}r autonome Fahrzeuge im Stadtverkehr. Die teilnehmenden PKWs m\"{u}ssen dabei Verkehrsregeln sowie andere Verkehrsteilnehmer ber\"{u}cksichtigen.},
author = {Ohl, Sebastian},
file = {:Users/paul/Dropbox/Promotion/Literatur/2011 - Ohl - Entwicklung einer Multi-Sensor-Datenfusion f\"{u}r ein autonomes Stra\ss enfahrzeug.pdf:pdf},
number = {2759270},
school = {TU Braunschweig},
title = {{Entwicklung einer Multi-Sensor-Datenfusion f\"{u}r ein autonomes Stra\ss enfahrzeug}},
url = {http://www.digibib.tu-bs.de/?docid=00041267},
year = {2011}
}
@article{Zhang2004,
author = {Zhang, Qilong and Pless, Robert},
file = {:Users/paul/Dropbox/Promotion/Literatur/2004 - Zhang, Pless - Extrinsic calibration of a camera and laser range finder.pdf:pdf},
journal = {IEEE International Conference on Intelligent Robots},
pages = {2301--2306},
publisher = {Ieee},
title = {{Extrinsic calibration of a camera and laser range finder}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1389752 http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Extrinsic+Calibration+of+a+Camera+and+Laser+Range+Finder\#2},
volume = {3},
year = {2004}
}
@article{Xiang2003,
annote = {2 Laser, Odometrie + Dempster-Shafer evidence theory + Kalman Filterung f\"{u}r Erkennung, Tracking usw.},
author = {Xiang, Zhiyu and Xu, Zezhong and Liu, Jilin},
file = {:Users/paul/Dropbox/Promotion/Literatur/2003 - Xiang, Xu, Liu - Small obstacle detection for autonomous land vehicle under semi-structural environments.pdf:pdf},
journal = {Intelligent Transportation Systems, 2003.},
pages = {293--298},
title = {{Small obstacle detection for autonomous land vehicle under semi-structural environments}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1251966},
year = {2003}
}
@inproceedings{Talukder2002,
author = {Talukder, A and Manduchi, R and Castano, R. and Owens, K and Matthies, L and Castano, A and Hogg, R},
booktitle = {Intelligent Robots and Systems, 2002. IEEE/RSJ International Conference on},
file = {:Users/paul/Dropbox/Promotion/Literatur/2002 - Talukder et al. - Autonomous terrain characterisation and modelling for dynamic control of unmanned vehicles.pdf:pdf},
keywords = {classification,driving in cross-country vegetated,environments re-,geometrical reasoning,navigation,obstacle detection obstacle negotiation,terrain modeling,terrain perception,vehicle modeling},
number = {818},
pages = {708--713},
publisher = {IEEE},
title = {{Autonomous terrain characterisation and modelling for dynamic control of unmanned vehicles}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1041474},
volume = {1},
year = {2002}
}
@article{St-Pierre2004,
annote = {UKF nearly same performance as EKF but EKF is computationally faster},
author = {St-Pierre, M and Gingras, D},
file = {:Users/paul/Dropbox/Promotion/Literatur/2004 - St-Pierre, Gingras - Comparison between the unscented Kalman filter and the extended Kalman filter for the position estimation mo.pdf:pdf},
journal = {Intelligent Vehicles Symposium, 2004 \ldots},
title = {{Comparison between the unscented Kalman filter and the extended Kalman filter for the position estimation module of an integrated navigation information system}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1336492},
year = {2004}
}
@phdthesis{Bohm2003,
abstract = {Die vorliegende Diplomarbeit beschreibt die Entwicklung eines Systems, um vorausfah- rende Fahrzeuge robust kamerabasiert zu vermessen. Da der f\"{u}r die Entfernungsmessung bew\"{a}hrte Radarsensor einen stark eingeschr\"{a}nkten Messbereich bez\"{u}glich naher Fahrzeu- ge auf anderen Spuren besitzt, wird die Distanzbestimmung durch kamerabasierte Metho- den erg\"{a}nzt.},
annote = {Appendix A mit guten Grundlagenerl\"{a}uterungen},
author = {B\"{o}hm, Thomas},
booktitle = {System},
file = {:Users/paul/Dropbox/Promotion/Literatur/2003 - B\"{o}hm - Erkennung und Verfolgung von Fahrzeugen im Videobild.pdf:pdf},
school = {Universit\"{a}t Stuttgart},
title = {{Erkennung und Verfolgung von Fahrzeugen im Videobild}},
year = {2003}
}
@article{Broggi2001,
author = {Broggi, Alberto and Bertozzi, Massimo and Fascioli, Alessandra},
file = {:Users/paul/Dropbox/Promotion/Literatur/2001 - Broggi, Bertozzi, Fascioli - Self-calibration of a stereo vision system for automotive applications.pdf:pdf},
journal = {Robotics and Automation, \ldots},
keywords = {autonomous vehicle,camera calibration,real-time image},
pages = {1--6},
title = {{Self-calibration of a stereo vision system for automotive applications}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=933193},
year = {2001}
}
@phdthesis{Rosenberg2005,
author = {von Rosenberg, Harald},
file = {:Users/paul/Dropbox/Promotion/Literatur/2005 - Rosenberg - Entwicklung eines elektronischen k\"{u}nstlichen Horizonts f\"{u}r kleine unbemannte Flugger\"{a}te.pdf:pdf},
school = {Universit\"{a}t Stuttgart},
title = {{Entwicklung eines elektronischen k\"{u}nstlichen Horizonts f\"{u}r kleine unbemannte Flugger\"{a}te}},
type = {Studienarbeit},
year = {2005}
}
@article{Mourikis2007,
abstract = {In this paper, we present an extended Kalman filter (EKF)-based algorithm for real-time vision-aided inertial navigation. The primary contribution of this work is the derivation of a measurement model that is able to express the geometric constraints that arise when a static feature is observed from multiple camera poses. This measurement model does not require including the 3D feature position in the state vector of the EKF and is optimal, up to linearization errors. The vision-aided inertial navigation algorithm we propose has computational complexity only linear in the number of features, and is capable of high-precision pose estimation in large-scale real-world environments. The performance of the algorithm is demonstrated in extensive experimental results, involving a camera/IMU system localizing within an urban area.},
author = {Mourikis, A.I. and Roumeliotis, S.I.},
doi = {10.1109/ROBOT.2007.364024},
isbn = {1-4244-0601-3},
issn = {1050-4729},
journal = {Proceedings 2007 IEEE International Conference on Robotics and Automation},
title = {{A Multi-State Constraint Kalman Filter for Vision-aided Inertial Navigation}},
year = {2007}
}
@article{Sukkarieh2008,
author = {Sukkarieh, S.},
doi = {10.1109/IROS.2008.4650637},
file = {:Users/paul/Dropbox/Promotion/Literatur/2008 - Sukkarieh - 3D smooth path planning for a UAV in cluttered natural environments.pdf:pdf},
isbn = {978-1-4244-2057-5},
journal = {2008 IEEE/RSJ International Conference on Intelligent Robots and Systems},
keywords = {Aerial Robotics,Field Robots},
month = sep,
pages = {794--800},
publisher = {Ieee},
title = {{3D smooth path planning for a UAV in cluttered natural environments}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4650637},
year = {2008}
}
@article{Ryu2002,
annote = {Zwei- Antennen GPS
        
Roll- und Pitch Estimation},
author = {Ryu, Jihan and Rossetter, EJ and Gerdes, JC},
file = {:Users/paul/Dropbox/Promotion/Literatur/2002 - Ryu, Rossetter, Gerdes - Vehicle sideslip and roll parameter estimation using GPS.pdf:pdf},
journal = {\ldots Symposium of Advanced Vehicle \ldots},
keywords = {estimation,gps,longitudinal velocity,parameter,roll,sideslip,slip angle,vehicle},
title = {{Vehicle sideslip and roll parameter estimation using GPS}},
url = {http://ddl.stanford.edu/sites/default/files/avec2002ryu.pdf},
year = {2002}
}
@article{Hornung2012,
author = {Hornung, Armin and Phillips, Mike},
doi = {10.1109/ICRA.2012.6225029},
file = {:Users/paul/Dropbox/Promotion/Literatur/2012 - Hornung, Phillips - Navigation in three-dimensional cluttered environments for mobile manipulation.pdf:pdf},
isbn = {978-1-4673-1405-3},
journal = {\ldots (ICRA), 2012 IEEE \ldots},
month = may,
pages = {423--429},
publisher = {Ieee},
title = {{Navigation in three-dimensional cluttered environments for mobile manipulation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6225029 http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6225029},
year = {2012}
}
@article{Travis2005,
author = {Travis, William and Simmons, AT and Bevly, DM},
file = {:Users/paul/Dropbox/Promotion/Literatur/2005 - Travis, Simmons, Bevly - Corridor navigation with a LiDARINS Kalman filter solution.pdf:pdf},
journal = {\ldots Vehicles Symposium, 2005. \ldots},
pages = {1--6},
title = {{Corridor navigation with a LiDAR/INS Kalman filter solution}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1505126},
year = {2005}
}
@book{Wender2008a,
author = {Wender, Stefan},
file = {:Users/paul/Dropbox/Promotion/Literatur/2008 - Wender - Multisensorsystem zur erweiterten Fahrzeugumfelderfassung.pdf:pdf},
title = {{Multisensorsystem zur erweiterten Fahrzeugumfelderfassung}},
url = {http://vts.uni-ulm.de/docs/2008/6605/vts\_6605\_9026.pdf},
year = {2008}
}
@article{Haberjahn2010,
abstract = {Ein Sensorsystem, bestehend aus einem 4-EbenenLaserscanner und einer Stereokamera, dient zur Erfassung des Fahrzeugumfeldes. Ziel ist es, Gefahrenpotentiale, zum Beispiel in Form weiterer Verkehrsteilnehmer, fr\"{u}hzeitig vorherzusehen. Im Folgenden wird ein neuartiger Ansatz zur konkurrierenden Fusion der Sensordaten auf der Punktebene vorgestellt.},
author = {Haberjahn, Mathias},
file = {:Users/paul/Dropbox/Promotion/Literatur/2010 - Haberjahn - Low-Level-Fusion eines Laserscanner- und Stereokamera-Systems in der Fahrzeugumfelderfassung.pdf:pdf},
journal = {Proc. of 3D-Nordost},
title = {{Low-Level-Fusion eines Laserscanner- und Stereokamera-Systems in der Fahrzeugumfelderfassung}},
url = {http://elib.dlr.de/68065/1/ws3dno2010\_mathias\_haberjahn\_final.pdf},
year = {2010}
}
@article{Scheunert2005,
abstract = {Dieser Artikelbefa\ss t sich mit einemTeilgebietderSzenenerkennung f\"{u}rFahrerassistenzsysteme. Multi-Sensor-Daten-Fusion wird f\"{u}rdie Detektion und zeitliche Verfolgung von Personen im Fahrzeugumfeld eingesetzt. Ein System, bestehendaus einem Laserscannerund einer Infrarot-Kamera wird verwendet, um Personen sicher zudetektieren undgenau zu lokalisieren.},
author = {Scheunert, Ullrich and Cramer, Heiko and Fardi, Basel and Wanielik, Gerd},
file = {:Users/paul/Dropbox/Promotion/Literatur/2005 - Scheunert et al. - Multi-Sensor-Daten-Fusion zur Personenerkennung mit dem Merkmalsmodell.pdf:pdf},
journal = {2005-Informatik LIVE},
pages = {297--301},
title = {{Multi-Sensor-Daten-Fusion zur Personenerkennung mit dem Merkmalsmodell}},
url = {http://subs.emis.de/LNI/Proceedings/Proceedings68/GI-Proceedings.68-62.pdf},
year = {2005}
}
@article{Thrun2003,
author = {Thrun, Sebastian},
file = {:Users/paul/Dropbox/Promotion/Literatur/2003 - Thrun - Learning occupancy grid maps with forward sensor models.pdf:pdf;:Users/paul/Dropbox/Promotion/Literatur/2003 - Thrun - Learning occupancy grid maps with forward sensor models(2).pdf:pdf},
journal = {Autonomous robots},
pages = {1--28},
title = {{Learning occupancy grid maps with forward sensor models}},
url = {http://www.springerlink.com/index/T3034763762H9469.pdf http://link.springer.com/article/10.1023/A:1025584807625},
year = {2003}
}
@article{Xu2006,
abstract = {Obstacle detection and road following are two foundational abilities in ALV autonomous navigation. Vision based method is not robust to different weather, illuminance, road surface condition. In this paper we use a laser rangefinder with four layers to implement obstacle detection and road following in outdoor environment. Obstacle detection is based on stochastic density of spatial scanning points. It can efficiently detect and track the artificial and natural obstacles. Road boundaries are modeled with two lines. A filter method is employed to track the parameters of road boundaries. Proposed method can perform the obstacle detection and road following simultaneously in day and night. It is free of shadow, bright spot and dirty road surface and more robust than vision based methods. All these techniques have been implemented on our ALV equipped with IBEO laser scanner.},
annote = {Sehr gutes Paper!Entscheidungsgrundlage ob Objekt oder nicht anhand von Anh\"{a}ufung von Punkten in gewisser Ellisenfl\"{a}che (Dichte) und Eigenwertverh\"{a}ltnisse der Kovarianzmatrix.Au\ss erdem diskretes Kalman-Filter Model f\"{u}r lineare Aneinanderreihung von Objekten (Poles in a row)},
author = {Xu, Zezhong and Zhuang, Yanbin and Chen, Huahua},
doi = {10.1109/WCICA.2006.1713665},
file = {:Users/paul/Dropbox/Promotion/Literatur/2006 - Xu, Zhuang, Chen - Obstacle Detection and Road Following using Laser Scanner.pdf:pdf},
isbn = {1424403324},
journal = {2006 6th World Congress on Intelligent Control and Automation},
pages = {8630--8634},
publisher = {Ieee},
title = {{Obstacle Detection and Road Following using Laser Scanner}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1713665},
volume = {2},
year = {2006}
}
@article{Weiss2007a,
author = {Weiss, Thorsten and Schiele, Bruno and Dietmayer, Klaus},
doi = {10.1109/IVS.2007.4290112},
file = {:Users/paul/Dropbox/Promotion/Literatur/2007 - Weiss, Schiele, Dietmayer - Robust driving path detection in urban and highway scenarios using a laser scanner and online occupan.pdf:pdf},
isbn = {1-4244-1067-3},
issn = {1931-0587},
journal = {2007 IEEE Intelligent Vehicles Symposium},
month = jun,
pages = {184--189},
publisher = {Ieee},
title = {{Robust driving path detection in urban and highway scenarios using a laser scanner and online occupancy grids}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4290112},
year = {2007}
}
@article{Madgwick2010,
annote = {Tinkerforge IMU Algorithmus},
author = {Madgwick, SOH},
file = {:Users/paul/Dropbox/Promotion/Literatur/2010 - Madgwick - An efficient orientation filter for inertial and inertialmagnetic sensor arrays.pdf:pdf},
journal = {Report x-io and University of Bristol},
title = {{An efficient orientation filter for inertial and inertial/magnetic sensor arrays}},
url = {http://sharenet-wii-motion-trac.googlecode.com/files/An\_efficient\_orientation\_filter\_for\_inertial\_and\_inertialmagnetic\_sensor\_arrays.pdf},
year = {2010}
}
@article{Singh1991,
author = {Singh, S and Keller, P.},
file = {:Users/paul/Dropbox/Promotion/Literatur/1991 - Singh, Keller - Obstacle detection for high speed autonomous navigation.pdf:pdf},
journal = {Robotics and Automation, 1991.},
title = {{Obstacle detection for high speed autonomous navigation}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=132057},
year = {1991}
}
@article{Elfes1986,
annote = {Erste Nennung von Occupancy Grids},
author = {Elfes, Alberto},
doi = {10.1109/ROBOT.1986.1087534},
file = {:Users/paul/Dropbox/Promotion/Literatur/1986 - Elfes - A sonar-based mapping and navigation system.pdf:pdf},
journal = {Robotics and Automation. Proceedings. 1986 IEEE \ldots},
pages = {1151--1156},
publisher = {Institute of Electrical and Electronics Engineers},
title = {{A sonar-based mapping and navigation system}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1087534 http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1087534},
volume = {3},
year = {1986}
}
@phdthesis{Stahn2009,
abstract = {In der vorliegenden Arbeit wird die Navigation mit modernen Laserscannern als Sensoren realisiert. Die Laserscanner-Technologie liefert zuverl\"{a}ssig genaue Entfernungsdaten auch bei variierenden Lichtverh\"{a}ltnissen und Witterungsbedingungen. Sie ist daher pr\"{a}- destiniert f\"{u}r alle Anwendungen im Innen- und Au\ss enbereich, bei denen eine pr\"{a}zise und robuste Relokalisation in Echtzeit erforderlich ist.},
author = {Stahn, Roland},
file = {:Users/paul/Dropbox/Promotion/Literatur/2009 - Stahn - Modellbasierte Merkmalsplanung zur objektbezogenen laserscannerbasierten Navigation von Fahrzeugen.pdf:pdf},
pages = {196},
school = {Technische Universit\"{a}t Berlin},
title = {{Modellbasierte Merkmalsplanung zur objektbezogenen laserscannerbasierten Navigation von Fahrzeugen}},
url = {http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:de:kobv:83-opus-26423},
year = {2009}
}
@phdthesis{Schindler2009,
author = {Schindler, Andreas},
file = {:Users/paul/Dropbox/Promotion/Literatur/2009 - Schindler - Neue Konzeption und erstmalige Realisierung eines aktiven Fahrwerks mit Preview-Strategie.pdf:pdf},
isbn = {9783866444355},
school = {Karlsruher Institut f\"{u}r Technologie},
title = {{Neue Konzeption und erstmalige Realisierung eines aktiven Fahrwerks mit Preview-Strategie}},
year = {2009}
}
@incollection{Dietmayer2005,
author = {Dietmayer, Klaus and Kaempchen, Nico and Fuerstenberg, Kay and Kibbel, J and Justus, W and Schulz, R},
booktitle = {Advanced Microsystems for Automotive Applications 2005 SE - 15},
doi = {10.1007/3-540-27463-4\_15},
editor = {Valldorf, J\"{u}rgen and Gessner, Wolfgang},
isbn = {978-3-540-24410-3},
keywords = {LIDAR,lane detection,multilayer laserscanner,roadway detection},
pages = {197--213},
publisher = {Springer Berlin Heidelberg},
series = {Advanced Microsystems for Automotive Applications 2005},
title = {{Roadway Detection and Lane Detection using Multilayer Laserscanner}},
url = {http://dx.doi.org/10.1007/3-540-27463-4\_15},
year = {2005}
}
@article{Zhao2009,
author = {Zhao, Huijing and Chiba, Masaki and Shibasaki, Ryosuke and Shao, Xiaowei},
file = {:Users/paul/Dropbox/Promotion/Literatur/2009 - Zhao et al. - A Laser-Scanner-Based Approach Toward Driving Safety and Traffic Data Collection.pdf:pdf},
journal = {Transportation},
number = {3},
pages = {534--546},
title = {{A Laser-Scanner-Based Approach Toward Driving Safety and Traffic Data Collection}},
volume = {10},
year = {2009}
}
@article{Adams1996,
author = {Adams, M.D.},
file = {:Users/paul/Dropbox/Promotion/Literatur/1996 - Adams - The interpretation of phase and intensity data from AMCW light detection sensors for reliable ranging.pdf:pdf},
journal = {The International journal of robotics},
keywords = {Charakterisierung,laserscanner},
title = {{The interpretation of phase and intensity data from AMCW light detection sensors for reliable ranging}},
url = {http://ijr.sagepub.com/content/15/5/441.short},
year = {1996}
}
@misc{Tacke2002,
author = {Tacke, Hermann},
file = {:Users/paul/Dropbox/Promotion/Literatur/2002 - Tacke - M\"{a}hvorrichtung zum M\"{a}hen eines Bereiches neben einem Tragmittel.pdf:pdf},
publisher = {Mulag Fahrzeugwerk GmbH \& Co KG},
title = {{M\"{a}hvorrichtung zum M\"{a}hen eines Bereiches neben einem Tragmittel}},
url = {http://www.freepatentsonline.com/EP1249157.pdf},
year = {2002}
}
@article{Chen2007,
abstract = {This paper describes a vehicle-borne mapping system which combines laser scanners, cameras and navigation unit for urban spatial object extraction especially the traffic signs/signals. Considering the high cost of searching candidates of urban spatial objects in images, candidates are searched in laser points. As laser scanners and cameras are calibrated into a common reference frame, laser points can be projected onto images to perform candidate verification. The combination of laser scanners and cameras can reduce the search space in images. Moreover laser points provide precise 3d position for the candidate.},
author = {Chen, Yu-zhong and Zhao, Hui-jing and Shibasaki, Ryosuke},
file = {:Users/paul/Dropbox/Promotion/Literatur/2007 - Chen, Zhao, Shibasaki - A MOBILE SYSTEM COMBINING LASER SCANNERS AND CAMERAS FOR URBAN SPATIAL OBJECTS EXTRACTION.pdf:pdf},
isbn = {142440973X},
journal = {International Conference on Machine Learning and Cybernetics,},
keywords = {Datafusion,Laserscanner,camera,video},
number = {August},
pages = {1729--1733},
title = {{A MOBILE SYSTEM COMBINING LASER SCANNERS AND CAMERAS FOR URBAN SPATIAL OBJECTS EXTRACTION}},
volume = {6},
year = {2007}
}
@article{Miyajima2013a,
annote = {\"{A}hnlich dem BMBF Projekt "Adaptive, lernende Systeme"},
author = {Miyajima, Chiyomi and Angkititrakul, Pongtep and Takeda, Kazuya},
issn = {2048-7703},
journal = {APSIPA Transactions on Signal and Information Processing},
keywords = {Behavioral signal processing,Driver behavior,Multi-modal driving signals,On-the-road},
language = {English},
month = mar,
pages = {e2},
publisher = {Cambridge University Press},
title = {{Behavior signal processing for vehicle applications}},
url = {http://journals.cambridge.org/abstract\_S2048770313000024},
volume = {2},
year = {2013}
}
@inproceedings{Fuerstenberg2000d,
author = {Fuerstenberg, K.C. and Hipp, J and Liebram, A and Others},
booktitle = {Proceedings of ITS},
file = {:Users/paul/Dropbox/Promotion/Literatur/2000 - Fuerstenberg et al. - A Laserscanner for detailed traffic data collection and traffic control.pdf:pdf},
pages = {1--4},
publisher = {Citeseer},
title = {{A Laserscanner for detailed traffic data collection and traffic control}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.24.4950\&amp;rep=rep1\&amp;type=pdf},
year = {2000}
}
@article{Gallego2009a,
author = {Gallego, Nieves and Mocholi, Antonio and Menendez, Miguel and Barrales, Raymundo},
doi = {10.1109/CERMA.2009.11},
file = {:Users/paul/Dropbox/Promotion/Literatur/2009 - Gallego et al. - Traffic Monitoring Improving Road Safety Using a Laser Scanner Sensor.pdf:pdf},
isbn = {978-0-7695-3799-3},
journal = {2009 Electronics, Robotics and Automotive Mechanics Conference (CERMA)},
keywords = {-intelligent sensors,detection sys-,intelligent transportation systems,laser scanner,tem,traffic parameters},
month = sep,
pages = {281--286},
publisher = {Ieee},
title = {{Traffic Monitoring: Improving Road Safety Using a Laser Scanner Sensor}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5341976},
year = {2009}
}
@inproceedings{Miller2013,
author = {Miller, Charlie and Valasek, Chris},
keywords = {CAN, Hack, OBD,Hack,OBD},
title = {{Adventures in Automotive Networks ans Control Units}},
url = {http://illmatics.com/car\_hacking.pdf},
year = {2013}
}
@inproceedings{Veichtlbauer2011a,
author = {Veichtlbauer, Armin and Dorfinger, Peter and Schrittesser, Ulrich},
booktitle = {SENSORCOMM 2011, The Fifth International Conference on Sensor Technologies and Applications},
file = {:Users/paul/Dropbox/Promotion/Literatur/2011 - Veichtlbauer, Dorfinger, Schrittesser - Live Data Acquisition for Situation Awareness in Traffic Management Systems Using Laser S.pdf:pdf},
isbn = {9781612081441},
keywords = {-situation awareness,Situation Awareness,Vehicle Counting,aware-,compensate for a situation,hicle counting,however the knowledge of,sensor data acquisition,the current distribution of,these parameters does not,traffic management,ve-},
number = {c},
pages = {268--273},
title = {{Live Data Acquisition for Situation Awareness in Traffic Management Systems Using Laser Sensors}},
url = {http://www.thinkmind.org/index.php?view=article\&amp;articleid=sensorcomm\_2011\_11\_10\_10074},
year = {2011}
}
@article{Bellucci2010b,
author = {Bellucci, Patrizia and Cipriani, Ernesto},
doi = {10.1007/s12544-010-0039-9},
file = {:Users/paul/Dropbox/Promotion/Literatur/2010 - Bellucci, Cipriani - Data accuracy on automatic traffic counting the SMART project results.pdf:pdf},
issn = {1867-0717},
journal = {European Transport Research Review},
keywords = {1108,70,accuracy,agencies have,measurement,n,providing an estimate of,roads,so far italian road,the importance and,traffic monitoring devices,usage of main national,validation procedure},
month = oct,
number = {4},
pages = {175--187},
title = {{Data accuracy on automatic traffic counting: the SMART project results}},
url = {http://www.springerlink.com/index/10.1007/s12544-010-0039-9},
volume = {2},
year = {2010}
}
@article{Homm2011a,
author = {Homm, Florian and Kaempchen, Nico},
isbn = {9781457708916},
journal = {Vehicles Symposium (IV),},
number = {Iv},
pages = {969--974},
title = {{Fusion of laserscannner and video based lanemarking detection for robust lateral vehicle control and lane change maneuvers}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5940424},
year = {2011}
}
@article{Weiss2007b,
abstract = {Detailed digital maps are of benefit for navigation systems and also for future driver assistant and safety applica- tions. The generation of detailed digital maps is an expensive and time-consuming process as there is much manual rework. In this work, algorithms for the automatic detection of traffic infrastructure objects are proposed. The accurate positions of lane markings, sidewalks, reflection posts and guardrails are determined automatically by a vertically and a horizontally mounted automotive laser scanner. The high position accuracy of the mapped traffic infrastructure objects allows for the rapid generation of up to date, accurate and detailed digital infrastructure maps with a cost efficient sensor setup and a low demand for manual rework.},
annote = {Koordinatentrafo von Sensor-->WGS84
        
AUTOMATIC MAPPING OF GUARDRAILS AND SIDEWALKS},
author = {Weiss, Thorsten},
isbn = {1424410681},
journal = {Intelligent Vehicles Symposium, 2007},
pages = {1271--1277},
title = {{Automatic detection of traffic infrastructure objects for the rapid generation of detailed digital maps using laser scanners}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4290293},
year = {2007}
}
@inproceedings{Hussain2005a,
author = {Hussain, K.F. and Moussa, G.S.},
booktitle = {Information Technology: Coding and Computing, 2005. ITCC 2005. International Conference on},
file = {:Users/paul/Dropbox/Promotion/Literatur/2005 - Hussain, Moussa - Automatic vehicle classification system using range sensor.pdf:pdf},
isbn = {0769523153},
pages = {107--112},
publisher = {IEEE},
title = {{Automatic vehicle classification system using range sensor}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1425130},
volume = {2},
year = {2005}
}
@inproceedings{Liu2007a,
abstract = {A monocular vision based detection algorithm is presented to detect rear vehicles. Our detection algorithm consist of two main steps: knowledge based hypothesis generation and appearance based hypothesis verification. In the hypothesis generation step, a shadow extraction method is proposed based on contrast sensitivity to extract regions of interest (ROI), it can effectively solve the problems caused by casting shadow and illuminations. In the hypothesis verification step, one improved wavelet feature extraction approach based on HSV space was proposed. Moreover, in order to satisfy different application requirements, a new method based on probability density function is proposed to decide the decision boundary for Support Vector Machine. The algorithm was tested under various traffic scenes at different daytime, the result illustrated good performance.},
author = {Liu, Wei and Song, Chunyan and Wen, Xuezhi and Yuan, Huai and Zhao, Hong F.},
booktitle = {2007 IEEE International Conference on Vehicular Electronics and Safety},
month = dec,
pages = {1--6},
publisher = {IEEE},
title = {{A monocular-vision rear vehicle detection algorithm}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=4456372\&contentType=Conference+Publications\&searchField=Search\_All\&queryText=vehicle+rear+laserscanner},
year = {2007}
}
@inproceedings{Luo2010b,
abstract = {Many papers concentrate on the 3*3 perspective transformation matrix calculation of bird's view system, but few discussed for the whole system implementation. In this paper, a low-cost bird's-eye view system is proposed, which adopts an elaborate software/hardware cooperative system structure. It can be applied to all kinds of vision-based system in vehicles directly as a ready-made module.},
author = {Luo, Lin-bo and Koh, In-Sung and Min, Kyeong-Yuk Yuk and Wang, Jun and Chong, Jong-Wha Wha},
booktitle = {2010 Digest of Technical Papers International Conference on Consumer Electronics (ICCE)},
file = {::},
month = jan,
pages = {311--312},
publisher = {IEEE},
title = {{Low-cost implementation of bird's-eye view system for camera-on-vehicle}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=5418845\&contentType=Conference+Publications\&searchField\%3DSearch\_All\%26queryText\%3Deye+birds+view},
year = {2010}
}
@inproceedings{Chen2012a,
abstract = {This paper puts forward a control method of vehicle rear-end anti-collision security system from the point of view of ensuring the traffic safety. The system makes full use of the electromagnetic devices which are installed on the trail of leading vehicle and the head of following vehicle. It uses the principle of electromagnetic repulsion of the same. When the leading vehicle suddenly slows down or has an emergency stopping, the devices open at the same time to increase the deceleration of following vehicle to set up an automatic auxiliary braking system. The purpose of the method is to avoid the driver's reaction delay and ensure the car safety immediately. Meanwhile, it can improve the efficiency of deceleration. This paper analyses the feasibility of the method from two aspects: safety distance and deceleration efficiency.},
author = {Chen, Meng and Liu, Fasheng and Ren, Chuanxiang and Gao, Zhimin},
booktitle = {2012 4th International Conference on Intelligent Human-Machine Systems and Cybernetics},
month = aug,
pages = {46--48},
publisher = {IEEE},
title = {{A Control System of Vehicle Rear-end Anti-collision}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=6305721\&contentType=Conference+Publications\&searchField=Search\_All\&queryText=vehicle+rear},
year = {2012}
}
@inproceedings{Liu2007b,
abstract = {A monocular vision based detection algorithm is presented to detect rear vehicles. Our detection algorithm consist of two main steps: knowledge based hypothesis generation and appearance based hypothesis verification. In the hypothesis generation step, a shadow extraction method is proposed based on contrast sensitivity to extract regions of interest (ROI), it can effectively solve the problems caused by casting shadow and illuminations. In the hypothesis verification step, one improved wavelet feature extraction approach based on HSV space was proposed. Moreover, in order to satisfy different application requirements, a new method based on probability density function is proposed to decide the decision boundary for Support Vector Machine. The algorithm was tested under various traffic scenes at different daytime, the result illustrated good performance.},
author = {Liu, Wei and Song, Chunyan and Wen, Xuezhi and Yuan, Huai and Zhao, Hong F.},
booktitle = {2007 IEEE International Conference on Vehicular Electronics and Safety},
month = dec,
pages = {1--6},
publisher = {IEEE},
title = {{A monocular-vision rear vehicle detection algorithm}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=4456372\&contentType=Conference+Publications\&searchField=Search\_All\&queryText=vehicle+rear+laserscanner},
year = {2007}
}
@inproceedings{Luo2010a,
abstract = {Many papers concentrate on the 3*3 perspective transformation matrix calculation of bird's view system, but few discussed for the whole system implementation. In this paper, a low-cost bird's-eye view system is proposed, which adopts an elaborate software/hardware cooperative system structure. It can be applied to all kinds of vision-based system in vehicles directly as a ready-made module.},
author = {Luo, Lin-bo and Koh, In-Sung and Min, Kyeong-Yuk Yuk and Wang, Jun and Chong, Jong-Wha Wha},
booktitle = {2010 Digest of Technical Papers International Conference on Consumer Electronics (ICCE)},
file = {::},
month = jan,
pages = {311--312},
publisher = {IEEE},
title = {{Low-cost implementation of bird's-eye view system for camera-on-vehicle}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=5418845\&contentType=Conference+Publications\&searchField=Search\_All\&queryText=eye+birds+view},
year = {2010}
}
@inproceedings{Luo2009a,
abstract = {Rear camera or other wide-angle camera mounted on vehicle has serious perspective effect which makes driver unable to feel distance correctly and is not helpful for succeeding image analysis. To remove perspective effect, it's necessary to change diagonal view to bird's-eye view. In this paper, a software-hardware cooperative bird's-eye view system is proposed, which can estimates the transformation matrix and changes the view automatically in real-time. The matrix estimation module is implemented by software, because it only needs to calculate once. The transformation part is implemented by hardware, because it must be done repetitively and it requires high computation power. To optimize hardware performance and save cost, three optimization approaches like one-step transformation, memory pre-estimation and look-up table (LUT) have been employed.},
author = {Luo, LinBo and Koh, InSung and Park, SangYoon and Ahn, ReSen and Chong, JongWha},
booktitle = {2009 IEEE International Conference on Network Infrastructure and Digital Content},
month = nov,
pages = {963--967},
publisher = {IEEE},
title = {{A software-hardware cooperative implementation of bird's-eye view system for camera-on-vehicle}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=5360920\&contentType=Conference+Publications\&searchField=Search\_All\&queryText=eye+birds+view+vehicle},
year = {2009}
}
@inproceedings{Xiong2011b,
abstract = {This paper proposed a method to integrate multiple images from a video captured by the camera sticked on the back of a vehicle. The integration can be performed in real time. The image integration consists of two steps: Perspective transform and stitching. First, do camera calibration to get the intrinsic parameters and extrinsic parameters with camera calibration and get the birds-eye view of each image. Then detect the line of each image using Hough Transform. After gained the line histogram, gets the rotation angle between two images using minimum cross-correlation of line histogram. Use minimum cross-correlation of binary images to get the transform pixel in horizontal direction and vertical direction. Do spatial transform for one image to gain the images' coordinate in the same coordinate system. Add two images with different weight to get stitching image.},
author = {Xiong, Zhonglong and Ying, Jie and Zhang, Renjie},
booktitle = {2011 International Conference on Multimedia Technology},
month = jul,
pages = {456--459},
publisher = {IEEE},
title = {{Research of bird's-eye panoramic view for vehicle parking}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=6003073\&contentType=Conference+Publications\&searchField=Search\_All\&queryText=eye+birds+view+vehicle+laserscanner},
year = {2011}
}
@inproceedings{Luo2009,
abstract = {Rear camera or other wide-angle camera mounted on vehicle has serious perspective effect which makes driver unable to feel distance correctly and is not helpful for succeeding image analysis. To remove perspective effect, it's necessary to change diagonal view to bird's-eye view. In this paper, a software-hardware cooperative bird's-eye view system is proposed, which can estimates the transformation matrix and changes the view automatically in real-time. The matrix estimation module is implemented by software, because it only needs to calculate once. The transformation part is implemented by hardware, because it must be done repetitively and it requires high computation power. To optimize hardware performance and save cost, three optimization approaches like one-step transformation, memory pre-estimation and look-up table (LUT) have been employed.},
author = {Luo, LinBo and Koh, InSung and Park, SangYoon and Ahn, ReSen and Chong, JongWha},
booktitle = {2009 IEEE International Conference on Network Infrastructure and Digital Content},
month = nov,
pages = {963--967},
publisher = {IEEE},
title = {{A software-hardware cooperative implementation of bird's-eye view system for camera-on-vehicle}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=5360920\&contentType=Conference+Publications\&searchField=Search\_All\&queryText=eye+birds+view+vehicle},
year = {2009}
}
@inproceedings{Luo2010,
abstract = {Many papers concentrate on the 3*3 perspective transformation matrix calculation of bird's view system, but few discussed for the whole system implementation. In this paper, a low-cost bird's-eye view system is proposed, which adopts an elaborate software/hardware cooperative system structure. It can be applied to all kinds of vision-based system in vehicles directly as a ready-made module.},
author = {Luo, Lin-bo and Koh, In-Sung and Min, Kyeong-Yuk Yuk and Wang, Jun and Chong, Jong-Wha Wha},
booktitle = {2010 Digest of Technical Papers International Conference on Consumer Electronics (ICCE)},
month = jan,
pages = {311--312},
publisher = {IEEE},
title = {{Low-cost implementation of bird's-eye view system for camera-on-vehicle}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=5418845\&contentType=Conference+Publications\&searchField=Search\_All\&queryText=eye+birds+view},
year = {2010}
}
@inproceedings{Takahashi,
abstract = {In this paper a new lane detection method is proposed for a highway lane departure warning system which hardware cost is reduced by using an existing wide-angle back monitor camera and an embedded CPU on the market. The extended Hough transform and a bird's-eye view image are effectively applied to perform realtime lane detection. The method was built on an embedded CPU (Hitachi SH2E) as software. Then the extended Hough transform was executed at less than 66 milliseconds.},
author = {Takahashi, A. and Ninomiya, Y. and Ohta, M. and Nishida, M. and Takayama, M.},
booktitle = {Intelligent Vehicle Symposium, 2002. IEEE},
pages = {148--153},
publisher = {IEEE},
title = {{Rear view lane detection by wide angle camera}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=1187943\&contentType=Conference+Publications\&searchField=Search\_All\&queryText=eye+birds+view+vehicle+rear},
volume = {1}
}
@inproceedings{Luo2010c,
abstract = {Many papers concentrate on the 3*3 perspective transformation matrix calculation of bird's view system, but few discussed for the whole system implementation. In this paper, a low-cost bird's-eye view system is proposed, which adopts an elaborate software/hardware cooperative system structure. It can be applied to all kinds of vision-based system in vehicles directly as a ready-made module.},
author = {Luo, Lin-bo and Koh, In-Sung and Min, Kyeong-Yuk Yuk and Wang, Jun and Chong, Jong-Wha Wha},
booktitle = {2010 Digest of Technical Papers International Conference on Consumer Electronics (ICCE)},
file = {::},
month = jan,
pages = {311--312},
publisher = {IEEE},
title = {{Low-cost implementation of bird's-eye view system for camera-on-vehicle}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=5418845\&contentType=Conference+Publications\&searchField=Search\_All\&queryText=eye+birds+view},
year = {2010}
}
@inproceedings{Han2012a,
abstract = {Rear-end collisions account for a significant proportion of traffic accidents in modern times. The specific components of intelligent anti-vehicle rear-end collision system was analyzed in this paper, other aspects as common types and design were also referred.},
author = {Han, Tianlong},
booktitle = {2012 Second International Conference on Intelligent System Design and Engineering Application},
month = jan,
pages = {728--731},
publisher = {IEEE},
title = {{Research on Intelligent Anti-vehicle Rear-Ends Collision System}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=6173309\&contentType=Conference+Publications\&searchField=Search\_All\&queryText=vehicle+rear},
year = {2012}
}
@inproceedings{Lin2010a,
abstract = {This paper proposes Topview Transform Model approach of the image coordinate transformation, which is to transform perspective projection image into its corresponding bird's eye version. A heuristic searching algorithm estimates the parameter values used to perform the transformation from the source image. Using this approach, it is not necessary to provide an exact intrinsic or extrinsic camera or installation parameters. The designed car parking assistant system can be installed at the rear end of the car, providing the driver with a clearer image of the area behind the car. The processing time can be reduced by storing and using the transformation matrix estimated from the first image frame for a sequence of video images. The transformation matrix can be stored as the Matrix Mapping Table, and loaded into the DSP platform to perform the transformation. Experimental results show that the proposed approaches can provide a clearer and more accurate bird's eye view to the driver of the car.},
author = {Lin, Chien-Chuan and Wang, Ming-Shi},
booktitle = {2010 International Computer Symposium (ICS2010)},
month = dec,
pages = {306--311},
publisher = {IEEE},
title = {{Topview Transform Model for the vehicle parking assistance system}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=5685496\&contentType=Conference+Publications\&searchField=Search\_All\&queryText=eye+birds+view+vehicle+rear},
year = {2010}
}
@inproceedings{Han2012b,
abstract = {Rear-end collisions account for a significant proportion of traffic accidents in modern times. The specific components of intelligent anti-vehicle rear-end collision system was analyzed in this paper, other aspects as common types and design were also referred.},
author = {Han, Tianlong},
booktitle = {2012 Second International Conference on Intelligent System Design and Engineering Application},
month = jan,
pages = {728--731},
publisher = {IEEE},
title = {{Research on Intelligent Anti-vehicle Rear-Ends Collision System}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=6173309\&contentType=Conference+Publications\&searchField=Search\_All\&queryText=vehicle+rear},
year = {2012}
}
@inproceedings{Xiong2011,
abstract = {This paper proposed a method to integrate multiple images from a video captured by the camera sticked on the back of a vehicle. The integration can be performed in real time. The image integration consists of two steps: Perspective transform and stitching. First, do camera calibration to get the intrinsic parameters and extrinsic parameters with camera calibration and get the birds-eye view of each image. Then detect the line of each image using Hough Transform. After gained the line histogram, gets the rotation angle between two images using minimum cross-correlation of line histogram. Use minimum cross-correlation of binary images to get the transform pixel in horizontal direction and vertical direction. Do spatial transform for one image to gain the images' coordinate in the same coordinate system. Add two images with different weight to get stitching image.},
author = {Xiong, Zhonglong and Ying, Jie and Zhang, Renjie},
booktitle = {2011 International Conference on Multimedia Technology},
month = jul,
pages = {456--459},
publisher = {IEEE},
title = {{Research of bird's-eye panoramic view for vehicle parking}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=6003073\&contentType=Conference+Publications\&searchField=Search\_All\&queryText=eye+birds+view+vehicle+laserscanner},
year = {2011}
}
@inproceedings{Chen2012,
abstract = {This paper puts forward a control method of vehicle rear-end anti-collision security system from the point of view of ensuring the traffic safety. The system makes full use of the electromagnetic devices which are installed on the trail of leading vehicle and the head of following vehicle. It uses the principle of electromagnetic repulsion of the same. When the leading vehicle suddenly slows down or has an emergency stopping, the devices open at the same time to increase the deceleration of following vehicle to set up an automatic auxiliary braking system. The purpose of the method is to avoid the driver's reaction delay and ensure the car safety immediately. Meanwhile, it can improve the efficiency of deceleration. This paper analyses the feasibility of the method from two aspects: safety distance and deceleration efficiency.},
author = {Chen, Meng and Liu, Fasheng and Ren, Chuanxiang and Gao, Zhimin},
booktitle = {2012 4th International Conference on Intelligent Human-Machine Systems and Cybernetics},
month = aug,
pages = {46--48},
publisher = {IEEE},
title = {{A Control System of Vehicle Rear-end Anti-collision}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=6305721\&contentType=Conference+Publications\&searchField=Search\_All\&queryText=vehicle+rear},
year = {2012}
}
@inproceedings{Luo2009b,
abstract = {Rear camera or other wide-angle camera mounted on vehicle has serious perspective effect which makes driver unable to feel distance correctly and is not helpful for succeeding image analysis. To remove perspective effect, it's necessary to change diagonal view to bird's-eye view. In this paper, a software-hardware cooperative bird's-eye view system is proposed, which can estimates the transformation matrix and changes the view automatically in real-time. The matrix estimation module is implemented by software, because it only needs to calculate once. The transformation part is implemented by hardware, because it must be done repetitively and it requires high computation power. To optimize hardware performance and save cost, three optimization approaches like one-step transformation, memory pre-estimation and look-up table (LUT) have been employed.},
author = {Luo, LinBo and Koh, InSung and Park, SangYoon and Ahn, ReSen and Chong, JongWha},
booktitle = {2009 IEEE International Conference on Network Infrastructure and Digital Content},
month = nov,
pages = {963--967},
publisher = {IEEE},
title = {{A software-hardware cooperative implementation of bird's-eye view system for camera-on-vehicle}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=5360920\&contentType=Conference+Publications\&searchField=Search\_All\&queryText=eye+birds+view+vehicle},
year = {2009}
}
@article{DiazAlonso2008b,
abstract = {Overtaking and lane changing are very dangerous driving maneuvers due to possible driver distraction and blind spots. We propose an aid system based on image processing to help the driver in these situations. The main purpose of an overtaking monitoring system is to segment the rear view and track the overtaking vehicle. We address this task with an optic-flow-driven scheme, focusing on the visual field in the side mirror by placing a camera on top of it. When driving a car, the ego-motion optic-flow pattern is very regular, i.e., all the static objects (such as trees, buildings on the roadside, or landmarks) move backwards. An overtaking vehicle, on the other hand, generates an optic-flow pattern in the opposite direction, i.e., moving forward toward the vehicle. This well-structured motion scenario facilitates the segmentation of regular motion patterns that correspond to the overtaking vehicle. Our approach is based on two main processing stages: First, the computation of optical flow in real time uses a customized digital signal processor (DSP) particularly designed for this task and, second, the tracking stage itself, based on motion pattern analysis, which we address using a standard processor. We present a validation benchmark scheme to evaluate the viability and robustness of the system using a set of overtaking vehicle sequences to determine a reliable vehicle-detection distance.},
author = {{Diaz Alonso}, J. and {Ros Vidal}, E. and Rotter, A. and Muhlenberg, M.},
issn = {0018-9545},
journal = {IEEE Transactions on Vehicular Technology},
month = sep,
number = {5},
pages = {2736--2746},
title = {{Lane-Change Decision Aid System Based on Motion-Driven Vehicle Tracking}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=4439300\&contentType=Journals+\&+Magazines\&searchField=Search\_All\&queryText=Rear-view+Vehicle+Detection},
volume = {57},
year = {2008}
}
@inproceedings{Liu2007,
abstract = {A monocular vision based detection algorithm is presented to detect rear vehicles. Our detection algorithm consist of two main steps: knowledge based hypothesis generation and appearance based hypothesis verification. In the hypothesis generation step, a shadow extraction method is proposed based on contrast sensitivity to extract regions of interest (ROI), it can effectively solve the problems caused by casting shadow and illuminations. In the hypothesis verification step, one improved wavelet feature extraction approach based on HSV space was proposed. Moreover, in order to satisfy different application requirements, a new method based on probability density function is proposed to decide the decision boundary for Support Vector Machine. The algorithm was tested under various traffic scenes at different daytime, the result illustrated good performance.},
author = {Liu, Wei and Song, Chunyan and Wen, Xuezhi and Yuan, Huai and Zhao, Hong F.},
booktitle = {2007 IEEE International Conference on Vehicular Electronics and Safety},
month = dec,
pages = {1--6},
publisher = {IEEE},
title = {{A monocular-vision rear vehicle detection algorithm}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=4456372\&contentType=Conference+Publications\&searchField=Search\_All\&queryText=vehicle+rear+laserscanner},
year = {2007}
}
@inproceedings{Xiong2011a,
abstract = {This paper proposed a method to integrate multiple images from a video captured by the camera sticked on the back of a vehicle. The integration can be performed in real time. The image integration consists of two steps: Perspective transform and stitching. First, do camera calibration to get the intrinsic parameters and extrinsic parameters with camera calibration and get the birds-eye view of each image. Then detect the line of each image using Hough Transform. After gained the line histogram, gets the rotation angle between two images using minimum cross-correlation of line histogram. Use minimum cross-correlation of binary images to get the transform pixel in horizontal direction and vertical direction. Do spatial transform for one image to gain the images' coordinate in the same coordinate system. Add two images with different weight to get stitching image.},
author = {Xiong, Zhonglong and Ying, Jie and Zhang, Renjie},
booktitle = {2011 International Conference on Multimedia Technology},
month = jul,
pages = {456--459},
publisher = {IEEE},
title = {{Research of bird's-eye panoramic view for vehicle parking}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=6003073\&contentType=Conference+Publications\&searchField=Search\_All\&queryText=eye+birds+view+vehicle+laserscanner},
year = {2011}
}
@inproceedings{Ying2010b,
abstract = {Based on the digital image processing theory, a new method of measuring the leading vehicle distance was proposed. The input image using the method of edge enhancement and morphological transformation was established, so the edges of objects were enhanced to identify. The target vehicle was identified and calibrated in the image by using the method of the obstacle detection by segmentation and decision tree. The relationship between coordinates value in image space and the data of the real space plane was established by applying the ray angles. Thus, through accessing to image pixel coordinates of the vehicle, the vehicle's actual position in the plane can be calculated. At last, the leading vehicle distance based on the calculating model of inverse perspective mapping was measured. By using software VC++, an experiment program was made. The experiment results prove that the method of measuring the leading vehicle distance is simple and effective. It can meet the requirement of intelligent vehicle technologies. It is an more available and more advanced method to calculate the leading vehicle distance.},
author = {Ying, Yan and Yuhui, Zhang},
booktitle = {2010 International Conference on Intelligent Computation Technology and Automation},
month = may,
pages = {674--677},
publisher = {IEEE},
title = {{Technique of Measuring Leading Vehicle Distance Based on Digital Image Processing Theory}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=5523029\&contentType=Conference+Publications\&searchField=Search\_All\&queryText=Inverse+Perspective+Mapping+vehicle},
year = {2010}
}
@inproceedings{Ying2010a,
abstract = {Based on the digital image processing theory, a new method of measuring the leading vehicle distance was proposed. The input image using the method of edge enhancement and morphological transformation was established, so the edges of objects were enhanced to identify. The target vehicle was identified and calibrated in the image by using the method of the obstacle detection by segmentation and decision tree. The relationship between coordinates value in image space and the data of the real space plane was established by applying the ray angles. Thus, through accessing to image pixel coordinates of the vehicle, the vehicle's actual position in the plane can be calculated. At last, the leading vehicle distance based on the calculating model of inverse perspective mapping was measured. By using software VC++, an experiment program was made. The experiment results prove that the method of measuring the leading vehicle distance is simple and effective. It can meet the requirement of intelligent vehicle technologies. It is an more available and more advanced method to calculate the leading vehicle distance.},
author = {Ying, Yan and Yuhui, Zhang},
booktitle = {2010 International Conference on Intelligent Computation Technology and Automation},
month = may,
pages = {674--677},
publisher = {IEEE},
title = {{Technique of Measuring Leading Vehicle Distance Based on Digital Image Processing Theory}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=5523029\&contentType=Conference+Publications\&searchField=Search\_All\&queryText=Inverse+Perspective+Mapping+vehicle},
year = {2010}
}
@inproceedings{Ying2010,
abstract = {Based on the digital image processing theory, a new method of measuring the leading vehicle distance was proposed. The input image using the method of edge enhancement and morphological transformation was established, so the edges of objects were enhanced to identify. The target vehicle was identified and calibrated in the image by using the method of the obstacle detection by segmentation and decision tree. The relationship between coordinates value in image space and the data of the real space plane was established by applying the ray angles. Thus, through accessing to image pixel coordinates of the vehicle, the vehicle's actual position in the plane can be calculated. At last, the leading vehicle distance based on the calculating model of inverse perspective mapping was measured. By using software VC++, an experiment program was made. The experiment results prove that the method of measuring the leading vehicle distance is simple and effective. It can meet the requirement of intelligent vehicle technologies. It is an more available and more advanced method to calculate the leading vehicle distance.},
author = {Ying, Yan and Yuhui, Zhang},
booktitle = {2010 International Conference on Intelligent Computation Technology and Automation},
month = may,
pages = {674--677},
publisher = {IEEE},
title = {{Technique of Measuring Leading Vehicle Distance Based on Digital Image Processing Theory}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=5523029\&contentType=Conference+Publications\&searchField=Search\_All\&queryText=Inverse+Perspective+Mapping+vehicle},
year = {2010}
}
@article{DiazAlonso2008a,
abstract = {Overtaking and lane changing are very dangerous driving maneuvers due to possible driver distraction and blind spots. We propose an aid system based on image processing to help the driver in these situations. The main purpose of an overtaking monitoring system is to segment the rear view and track the overtaking vehicle. We address this task with an optic-flow-driven scheme, focusing on the visual field in the side mirror by placing a camera on top of it. When driving a car, the ego-motion optic-flow pattern is very regular, i.e., all the static objects (such as trees, buildings on the roadside, or landmarks) move backwards. An overtaking vehicle, on the other hand, generates an optic-flow pattern in the opposite direction, i.e., moving forward toward the vehicle. This well-structured motion scenario facilitates the segmentation of regular motion patterns that correspond to the overtaking vehicle. Our approach is based on two main processing stages: First, the computation of optical flow in real time uses a customized digital signal processor (DSP) particularly designed for this task and, second, the tracking stage itself, based on motion pattern analysis, which we address using a standard processor. We present a validation benchmark scheme to evaluate the viability and robustness of the system using a set of overtaking vehicle sequences to determine a reliable vehicle-detection distance.},
author = {{Diaz Alonso}, J. and {Ros Vidal}, E. and Rotter, A. and Muhlenberg, M.},
issn = {0018-9545},
journal = {IEEE Transactions on Vehicular Technology},
month = sep,
number = {5},
pages = {2736--2746},
title = {{Lane-Change Decision Aid System Based on Motion-Driven Vehicle Tracking}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=4439300\&contentType=Journals+\&+Magazines\&searchField=Search\_All\&queryText=Rear-view+Vehicle+Detection},
volume = {57},
year = {2008}
}
@inproceedings{Lin2010,
abstract = {This paper proposes Topview Transform Model approach of the image coordinate transformation, which is to transform perspective projection image into its corresponding bird's eye version. A heuristic searching algorithm estimates the parameter values used to perform the transformation from the source image. Using this approach, it is not necessary to provide an exact intrinsic or extrinsic camera or installation parameters. The designed car parking assistant system can be installed at the rear end of the car, providing the driver with a clearer image of the area behind the car. The processing time can be reduced by storing and using the transformation matrix estimated from the first image frame for a sequence of video images. The transformation matrix can be stored as the Matrix Mapping Table, and loaded into the DSP platform to perform the transformation. Experimental results show that the proposed approaches can provide a clearer and more accurate bird's eye view to the driver of the car.},
author = {Lin, Chien-Chuan and Wang, Ming-Shi},
booktitle = {2010 International Computer Symposium (ICS2010)},
month = dec,
pages = {306--311},
publisher = {IEEE},
title = {{Topview Transform Model for the vehicle parking assistance system}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=5685496\&contentType=Conference+Publications\&searchField=Search\_All\&queryText=eye+birds+view+vehicle+rear},
year = {2010}
}
@inproceedings{Kim2005,
abstract = {Active research into vehicle detection and tracking using a vision sensor are done for driver assistance systems (DAS) - collision warning and avoidance, vision enhancement, etc. The vehicle detection and tracking algorithm for DAS requires a robust feature extraction and tracking method regardless of the light and road conditions and an exact estimation of vehicle position and velocity regardless of the distance from the ego-vehicle. But most research was carried out in the day time with good lighting conditions and the little research done so far in the night time assumed no interference of headlights from other vehicles. This paper proposes a new robust vehicle detection and tracking method regardless of the light and road conditions at any distance using vision and sonar sensors. We use the sonar sensor for detection and distance estimation within 10 m and the image sensor over 10 m. First, this paper proposes a simple method that can determine the light condition by observing several images and this light condition is used by selecting one of several detection methods. The proposed vehicle detection method in the day time image can extract the shadow region represented by the boundary between a vehicle and the road and further verify using other vehicle features, such as symmetry rate, vertical edge, and lane information. The vehicle tracking method in the day time uses online template matching using the mean image created by several consecutive detection results. The vehicle detection method in the night time extracts bright regions caused by the headlights, taillights, brake lights, etc. and these candidates are verified by observing several consecutive frames.},
author = {Kim, Sam-Yong and Oh, Se-young Y. and Kang, Jeong-Gwan and Ryu, Young-Woo and Kim, Kwangsoo Soo and Park, Sang-Cheol and Park, KyongHa},
booktitle = {2005 IEEE/RSJ International Conference on Intelligent Robots and Systems},
pages = {2173--2178},
publisher = {IEEE},
title = {{Front and rear vehicle detection and tracking in the day and night times using vision and sonar sensor fusion}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=1545321\&contentType=Conference+Publications\&searchField=Search\_All\&queryText=vehicle+rear+laserscanner},
year = {2005}
}
@inproceedings{Kato2008b,
abstract = {This paper proposed a method for generating bird's eye view images using multi-cameras set in high points at intersections. As the generated images follows own vehicle's motion and includes the vehicle itself it enables the driver handing the surrounding situations conveniently. Experiments have shown the advantages of our method in save driving supporting.},
author = {Kato, Jien and Sekiyama, Noritaka},
booktitle = {2008 3rd International Conference on Innovative Computing Information and Control},
pages = {16--16},
publisher = {IEEE},
title = {{Generating Bird's Eye View Images Depending on Vehicle Positions by View Interpolation}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=4603205\&contentType=Conference+Publications\&searchField=Search\_All\&queryText=eye+birds+view+vehicle+laserscanner},
year = {2008}
}
@inproceedings{Kato2008a,
abstract = {This paper proposed a method for generating bird's eye view images using multi-cameras set in high points at intersections. As the generated images follows own vehicle's motion and includes the vehicle itself it enables the driver handing the surrounding situations conveniently. Experiments have shown the advantages of our method in save driving supporting.},
author = {Kato, Jien and Sekiyama, Noritaka},
booktitle = {2008 3rd International Conference on Innovative Computing Information and Control},
pages = {16--16},
publisher = {IEEE},
title = {{Generating Bird's Eye View Images Depending on Vehicle Positions by View Interpolation}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=4603205\&contentType=Conference+Publications\&searchField=Search\_All\&queryText=eye+birds+view+vehicle+laserscanner},
year = {2008}
}
@article{Hea,
abstract = {In this paper, we implement a method to detect obstacles around the vehicle by optical flow computation based on inverse perspective mapping. However, this approach had been proposed and used on the vehicle. But this approach is limited on a trajectory of the vehicle which moves along with a straight line. If the trajectory of the vehicle moves along with an arc line, the optical flow values will inconsistent in the left side and in the right side of this image which causes mistakes in obstacle detection. So we propose a method to improve this problem which uses the trajectory of vehicle to calculate the center of turning circle. And the center of turning circle can be used to adjust the inconsistent with optical flow values. After our improvement, the optical flow values can keep consistence even if the trajectory is along with an arc line.},
author = {He, Chin-Yi and Hong, Chao-Tse and Lo, Rong-Chin},
title = {{An improved obstacle detection using optical flow adjusting based on inverse perspective mapping for the vehicle safety}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=6473458\&contentType=Conference+Publications\&searchField=Search\_All\&queryText=Inverse+Perspective+Mapping+vehicle}
}
@article{He,
abstract = {In this paper, we implement a method to detect obstacles around the vehicle by optical flow computation based on inverse perspective mapping. However, this approach had been proposed and used on the vehicle. But this approach is limited on a trajectory of the vehicle which moves along with a straight line. If the trajectory of the vehicle moves along with an arc line, the optical flow values will inconsistent in the left side and in the right side of this image which causes mistakes in obstacle detection. So we propose a method to improve this problem which uses the trajectory of vehicle to calculate the center of turning circle. And the center of turning circle can be used to adjust the inconsistent with optical flow values. After our improvement, the optical flow values can keep consistence even if the trajectory is along with an arc line.},
author = {He, Chin-Yi and Hong, Chao-Tse and Lo, Rong-Chin},
title = {{An improved obstacle detection using optical flow adjusting based on inverse perspective mapping for the vehicle safety}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=6473458\&contentType=Conference+Publications\&searchField=Search\_All\&queryText=Inverse+Perspective+Mapping+vehicle}
}
@inproceedings{Han2012,
abstract = {Rear-end collisions account for a significant proportion of traffic accidents in modern times. The specific components of intelligent anti-vehicle rear-end collision system was analyzed in this paper, other aspects as common types and design were also referred.},
author = {Han, Tianlong},
booktitle = {2012 Second International Conference on Intelligent System Design and Engineering Application},
month = jan,
pages = {728--731},
publisher = {IEEE},
title = {{Research on Intelligent Anti-vehicle Rear-Ends Collision System}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=6173309\&contentType=Conference+Publications\&searchField=Search\_All\&queryText=vehicle+rear},
year = {2012}
}
@article{Heb,
abstract = {In this paper, we implement a method to detect obstacles around the vehicle by optical flow computation based on inverse perspective mapping. However, this approach had been proposed and used on the vehicle. But this approach is limited on a trajectory of the vehicle which moves along with a straight line. If the trajectory of the vehicle moves along with an arc line, the optical flow values will inconsistent in the left side and in the right side of this image which causes mistakes in obstacle detection. So we propose a method to improve this problem which uses the trajectory of vehicle to calculate the center of turning circle. And the center of turning circle can be used to adjust the inconsistent with optical flow values. After our improvement, the optical flow values can keep consistence even if the trajectory is along with an arc line.},
author = {He, Chin-Yi and Hong, Chao-Tse and Lo, Rong-Chin},
title = {{An improved obstacle detection using optical flow adjusting based on inverse perspective mapping for the vehicle safety}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=6473458\&contentType=Conference+Publications\&searchField=Search\_All\&queryText=Inverse+Perspective+Mapping+vehicle}
}
@inproceedings{Chen2012b,
abstract = {This paper puts forward a control method of vehicle rear-end anti-collision security system from the point of view of ensuring the traffic safety. The system makes full use of the electromagnetic devices which are installed on the trail of leading vehicle and the head of following vehicle. It uses the principle of electromagnetic repulsion of the same. When the leading vehicle suddenly slows down or has an emergency stopping, the devices open at the same time to increase the deceleration of following vehicle to set up an automatic auxiliary braking system. The purpose of the method is to avoid the driver's reaction delay and ensure the car safety immediately. Meanwhile, it can improve the efficiency of deceleration. This paper analyses the feasibility of the method from two aspects: safety distance and deceleration efficiency.},
author = {Chen, Meng and Liu, Fasheng and Ren, Chuanxiang and Gao, Zhimin},
booktitle = {2012 4th International Conference on Intelligent Human-Machine Systems and Cybernetics},
month = aug,
pages = {46--48},
publisher = {IEEE},
title = {{A Control System of Vehicle Rear-end Anti-collision}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=6305721\&contentType=Conference+Publications\&searchField=Search\_All\&queryText=vehicle+rear},
year = {2012}
}
@inproceedings{Takahashia,
abstract = {In this paper a new lane detection method is proposed for a highway lane departure warning system which hardware cost is reduced by using an existing wide-angle back monitor camera and an embedded CPU on the market. The extended Hough transform and a bird's-eye view image are effectively applied to perform realtime lane detection. The method was built on an embedded CPU (Hitachi SH2E) as software. Then the extended Hough transform was executed at less than 66 milliseconds.},
author = {Takahashi, A. and Ninomiya, Y. and Ohta, M. and Nishida, M. and Takayama, M.},
booktitle = {Intelligent Vehicle Symposium, 2002. IEEE},
pages = {148--153},
publisher = {IEEE},
title = {{Rear view lane detection by wide angle camera}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=1187943\&contentType=Conference+Publications\&searchField=Search\_All\&queryText=eye+birds+view+vehicle+rear},
volume = {1}
}
@inproceedings{Kato2008,
abstract = {This paper proposed a method for generating bird's eye view images using multi-cameras set in high points at intersections. As the generated images follows own vehicle's motion and includes the vehicle itself it enables the driver handing the surrounding situations conveniently. Experiments have shown the advantages of our method in save driving supporting.},
author = {Kato, Jien and Sekiyama, Noritaka},
booktitle = {2008 3rd International Conference on Innovative Computing Information and Control},
pages = {16--16},
publisher = {IEEE},
title = {{Generating Bird's Eye View Images Depending on Vehicle Positions by View Interpolation}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=4603205\&contentType=Conference+Publications\&searchField=Search\_All\&queryText=eye+birds+view+vehicle+laserscanner},
year = {2008}
}
@inproceedings{Takahashib,
abstract = {In this paper a new lane detection method is proposed for a highway lane departure warning system which hardware cost is reduced by using an existing wide-angle back monitor camera and an embedded CPU on the market. The extended Hough transform and a bird's-eye view image are effectively applied to perform realtime lane detection. The method was built on an embedded CPU (Hitachi SH2E) as software. Then the extended Hough transform was executed at less than 66 milliseconds.},
author = {Takahashi, A. and Ninomiya, Y. and Ohta, M. and Nishida, M. and Takayama, M.},
booktitle = {Intelligent Vehicle Symposium, 2002. IEEE},
pages = {148--153},
publisher = {IEEE},
title = {{Rear view lane detection by wide angle camera}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=1187943\&contentType=Conference+Publications\&searchField=Search\_All\&queryText=eye+birds+view+vehicle+rear},
volume = {1}
}
@inproceedings{Kim2005b,
abstract = {Active research into vehicle detection and tracking using a vision sensor are done for driver assistance systems (DAS) - collision warning and avoidance, vision enhancement, etc. The vehicle detection and tracking algorithm for DAS requires a robust feature extraction and tracking method regardless of the light and road conditions and an exact estimation of vehicle position and velocity regardless of the distance from the ego-vehicle. But most research was carried out in the day time with good lighting conditions and the little research done so far in the night time assumed no interference of headlights from other vehicles. This paper proposes a new robust vehicle detection and tracking method regardless of the light and road conditions at any distance using vision and sonar sensors. We use the sonar sensor for detection and distance estimation within 10 m and the image sensor over 10 m. First, this paper proposes a simple method that can determine the light condition by observing several images and this light condition is used by selecting one of several detection methods. The proposed vehicle detection method in the day time image can extract the shadow region represented by the boundary between a vehicle and the road and further verify using other vehicle features, such as symmetry rate, vertical edge, and lane information. The vehicle tracking method in the day time uses online template matching using the mean image created by several consecutive detection results. The vehicle detection method in the night time extracts bright regions caused by the headlights, taillights, brake lights, etc. and these candidates are verified by observing several consecutive frames.},
author = {Kim, Sam-Yong and Oh, Se-young Y. and Kang, Jeong-Gwan and Ryu, Young-Woo and Kim, Kwangsoo Soo and Park, Sang-Cheol and Park, KyongHa},
booktitle = {2005 IEEE/RSJ International Conference on Intelligent Robots and Systems},
pages = {2173--2178},
publisher = {IEEE},
title = {{Front and rear vehicle detection and tracking in the day and night times using vision and sonar sensor fusion}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=1545321\&contentType=Conference+Publications\&searchField=Search\_All\&queryText=vehicle+rear+laserscanner},
year = {2005}
}
@article{DiazAlonso2008,
abstract = {Overtaking and lane changing are very dangerous driving maneuvers due to possible driver distraction and blind spots. We propose an aid system based on image processing to help the driver in these situations. The main purpose of an overtaking monitoring system is to segment the rear view and track the overtaking vehicle. We address this task with an optic-flow-driven scheme, focusing on the visual field in the side mirror by placing a camera on top of it. When driving a car, the ego-motion optic-flow pattern is very regular, i.e., all the static objects (such as trees, buildings on the roadside, or landmarks) move backwards. An overtaking vehicle, on the other hand, generates an optic-flow pattern in the opposite direction, i.e., moving forward toward the vehicle. This well-structured motion scenario facilitates the segmentation of regular motion patterns that correspond to the overtaking vehicle. Our approach is based on two main processing stages: First, the computation of optical flow in real time uses a customized digital signal processor (DSP) particularly designed for this task and, second, the tracking stage itself, based on motion pattern analysis, which we address using a standard processor. We present a validation benchmark scheme to evaluate the viability and robustness of the system using a set of overtaking vehicle sequences to determine a reliable vehicle-detection distance.},
author = {{Diaz Alonso}, J. and {Ros Vidal}, E. and Rotter, A. and Muhlenberg, M.},
issn = {0018-9545},
journal = {IEEE Transactions on Vehicular Technology},
month = sep,
number = {5},
pages = {2736--2746},
title = {{Lane-Change Decision Aid System Based on Motion-Driven Vehicle Tracking}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=4439300\&contentType=Journals+\%26+Magazines\&searchField\%3DSearch\_All\%26queryText\%3DRear-view+Vehicle+Detection},
volume = {57},
year = {2008}
}
@inproceedings{Kim2005a,
abstract = {Active research into vehicle detection and tracking using a vision sensor are done for driver assistance systems (DAS) - collision warning and avoidance, vision enhancement, etc. The vehicle detection and tracking algorithm for DAS requires a robust feature extraction and tracking method regardless of the light and road conditions and an exact estimation of vehicle position and velocity regardless of the distance from the ego-vehicle. But most research was carried out in the day time with good lighting conditions and the little research done so far in the night time assumed no interference of headlights from other vehicles. This paper proposes a new robust vehicle detection and tracking method regardless of the light and road conditions at any distance using vision and sonar sensors. We use the sonar sensor for detection and distance estimation within 10 m and the image sensor over 10 m. First, this paper proposes a simple method that can determine the light condition by observing several images and this light condition is used by selecting one of several detection methods. The proposed vehicle detection method in the day time image can extract the shadow region represented by the boundary between a vehicle and the road and further verify using other vehicle features, such as symmetry rate, vertical edge, and lane information. The vehicle tracking method in the day time uses online template matching using the mean image created by several consecutive detection results. The vehicle detection method in the night time extracts bright regions caused by the headlights, taillights, brake lights, etc. and these candidates are verified by observing several consecutive frames.},
author = {Kim, Sam-Yong and Oh, Se-young Y. and Kang, Jeong-Gwan and Ryu, Young-Woo and Kim, Kwangsoo Soo and Park, Sang-Cheol and Park, KyongHa},
booktitle = {2005 IEEE/RSJ International Conference on Intelligent Robots and Systems},
pages = {2173--2178},
publisher = {IEEE},
title = {{Front and rear vehicle detection and tracking in the day and night times using vision and sonar sensor fusion}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=1545321\&contentType=Conference+Publications\&searchField=Search\_All\&queryText=vehicle+rear+laserscanner},
year = {2005}
}
@inproceedings{Lin2010b,
abstract = {This paper proposes Topview Transform Model approach of the image coordinate transformation, which is to transform perspective projection image into its corresponding bird's eye version. A heuristic searching algorithm estimates the parameter values used to perform the transformation from the source image. Using this approach, it is not necessary to provide an exact intrinsic or extrinsic camera or installation parameters. The designed car parking assistant system can be installed at the rear end of the car, providing the driver with a clearer image of the area behind the car. The processing time can be reduced by storing and using the transformation matrix estimated from the first image frame for a sequence of video images. The transformation matrix can be stored as the Matrix Mapping Table, and loaded into the DSP platform to perform the transformation. Experimental results show that the proposed approaches can provide a clearer and more accurate bird's eye view to the driver of the car.},
author = {Lin, Chien-Chuan and Wang, Ming-Shi},
booktitle = {2010 International Computer Symposium (ICS2010)},
month = dec,
pages = {306--311},
publisher = {IEEE},
title = {{Topview Transform Model for the vehicle parking assistance system}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=5685496\&contentType=Conference+Publications\&searchField=Search\_All\&queryText=eye+birds+view+vehicle+rear},
year = {2010}
}